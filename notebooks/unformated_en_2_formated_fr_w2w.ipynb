{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "unformated_en_2_formated_fr_w2w.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nb67W9VFEWrq"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "576a72a5a25a4718a02cd9f3115763c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b2f77ceaa5e4ea1a0c026ef94a5545d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c864fe5e282d465ab4d52201bc467708",
              "IPY_MODEL_9aa2e3fb54b34c499b0431d1a05193ea"
            ]
          }
        },
        "6b2f77ceaa5e4ea1a0c026ef94a5545d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c864fe5e282d465ab4d52201bc467708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ea849e1fc4c4d878d77c1c0b9074df2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 27,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 27,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9949c5b9b2c3418e98c83925a8e4e238"
          }
        },
        "9aa2e3fb54b34c499b0431d1a05193ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d67aa9ddd62c4ed4bcdf0afa48bf9335",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 27/27 [25:28&lt;00:00, 56.62s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_956330d18a344b9eb3a69e49fdb7c99d"
          }
        },
        "6ea849e1fc4c4d878d77c1c0b9074df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9949c5b9b2c3418e98c83925a8e4e238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d67aa9ddd62c4ed4bcdf0afa48bf9335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "956330d18a344b9eb3a69e49fdb7c99d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa53052d9f9b49b7988e43691a6f25cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ff43743d693467cb5ecb2c4c34fe62b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c57b46ccdd404fceb0686a997a81c132",
              "IPY_MODEL_bc76a5e4768d4cf393c94c2afed62063"
            ]
          }
        },
        "4ff43743d693467cb5ecb2c4c34fe62b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c57b46ccdd404fceb0686a997a81c132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a2fcdf19f254c11b05d25aca8e1570d",
            "_dom_classes": [],
            "description": "  3%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93435c458c664099abb6025ba22d7d8c"
          }
        },
        "bc76a5e4768d4cf393c94c2afed62063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac6341ed7b804e88baf5cd3f32162d0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/100 [01:07&lt;33:07, 20.49s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81b1dfb14856459ca663f0bb167f02ea"
          }
        },
        "4a2fcdf19f254c11b05d25aca8e1570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93435c458c664099abb6025ba22d7d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac6341ed7b804e88baf5cd3f32162d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81b1dfb14856459ca663f0bb167f02ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "jmjh290raIky",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxLx0cxT_fJ7",
        "colab_type": "text"
      },
      "source": [
        "### Colab stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWqhS7vxL8sr",
        "colab_type": "code",
        "outputId": "decb0948-504a-497b-e919-50daae2da5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqoNO6SIMIir",
        "colab_type": "code",
        "outputId": "28e0645e-1559-4f60-fa61-ad84e71d5a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install gensim==3.8.1\n",
        "!pip install sacrebleu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.6/dist-packages (3.8.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.11.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.18.2)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.12.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (1.12.39)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (1.15.39)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim==3.8.1) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim==3.8.1) (0.15.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.6)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (0.996.5)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWdkK1xIL5IO",
        "colab_type": "code",
        "outputId": "702901b8-8e4c-438f-8258-53ff6f5d4eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.chdir(os.path.join('drive', 'My Drive', 'ift6759', 'ift6759-t6-p2'))\n",
        "os.getcwd()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/ift6759/ift6759-t6-p2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYDRwI_X_oSc",
        "colab_type": "text"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKXrS5VKKORC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sacrebleu\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from dataloader.dataloader import get_dataset_train\n",
        "from utils.data import preprocess_v2id, postprocessing\n",
        "from utils.data import save_json, load_json, swap_dict_key_value, checkout_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3SG8WxB_q4E",
        "colab_type": "text"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAt-tC85KwQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_preprocess(data):\n",
        "    encoder_v2id, encoder_dataset = preprocess_v2id(\n",
        "            data=data,\n",
        "            v2id=os.path.join(\"language_models\",\"unformated_en_w2w\", \"v2id.json\"),\n",
        "            tokenize_type=\"w\",\n",
        "            max_seq=None,\n",
        "            remove_punctuation=True,\n",
        "            lower=False,\n",
        "            threshold=0.85,\n",
        "            CAP=True,\n",
        "            NUM=True,\n",
        "            ALNUM=True,\n",
        "            UPPER=True,\n",
        "            fasttext_model=\"/content/drive/My Drive/ift6759/ift6759-t6-p2/embeddings/unformated_en_w2w/128/unaligned_unformated_en\",\n",
        "    )\n",
        "    encoder_id2v = swap_dict_key_value(encoder_v2id)\n",
        "    return encoder_dataset, encoder_v2id, encoder_id2v\n",
        "\n",
        "def decoder_preprocess(data):\n",
        "    decoder_v2id, decoder_dataset = preprocess_v2id(\n",
        "            data=data,\n",
        "            v2id=os.path.join(\"language_models\",\"formated_fr_w2w\", \"v2id.json\"),\n",
        "            tokenize_type=\"w\",\n",
        "            max_seq=None,\n",
        "            remove_punctuation=False,\n",
        "            lower=False,\n",
        "            threshold=0.85,\n",
        "            CAP=True,\n",
        "            NUM=True,\n",
        "            ALNUM=True,\n",
        "            UPPER=True,\n",
        "            fasttext_model=\"/content/drive/My Drive/ift6759/ift6759-t6-p2/embeddings/formated_fr_w2w/128/unaligned_formated_fr\",\n",
        "    )\n",
        "    decoder_id2v = swap_dict_key_value(decoder_v2id)\n",
        "    return decoder_dataset, decoder_v2id, decoder_id2v\n",
        "\n",
        "def postprocess(out, encoder_v2id, decoder_v2id, enc_data_words):\n",
        "    func = postprocessing(\n",
        "                dec_data=out,\n",
        "                dec_v2id=decoder_v2id,\n",
        "                Print=False,\n",
        "                tokenize_type=\"w\",\n",
        "                fasttext_model=\"/content/drive/My Drive/ift6759/ift6759-t6-p2/embeddings/unformated_en_w2w/128/unaligned_unformated_en\",\n",
        "                enc_data=enc_data_words,\n",
        "                remove_punctuation=True,\n",
        "                lower=False,\n",
        "                CAP=True,\n",
        "                NUM=True,\n",
        "                ALNUM=True,\n",
        "                UPPER=True,\n",
        "                enc_v2id=encoder_v2id\n",
        "            )\n",
        "    return func\n",
        "\n",
        "def get_gen(data, batch_size, valid_test=False):\n",
        "    def data_word_generator():\n",
        "        ch_data = checkout_data(data)\n",
        "        if valid_test:\n",
        "          ch_data = ch_data[int(-len(ch_data)*0.2):]\n",
        "        size = len(ch_data)\n",
        "        steps = size//batch_size + 1\n",
        "        init = 0\n",
        "        end = batch_size\n",
        "        for i in range(steps):\n",
        "            to_return = ch_data[init:end]\n",
        "            init = end\n",
        "            end += batch_size\n",
        "            yield to_return\n",
        "    return data_word_generator()\n",
        "\n",
        "def get_out(enc_data_words):\n",
        "    enc_data_int, _, _ = encoder_preprocess(data=enc_data_words)\n",
        "    out, _ = evaluate(enc_data_int)\n",
        "    out_words = postprocess(out, encoder_v2id, decoder_v2id, enc_data_words)\n",
        "    return out_words\n",
        "\n",
        "def write_file_append(data, output):\n",
        "    with open(output, 'a+') as stream:\n",
        "      for line in data:\n",
        "        stream.write(line)\n",
        "        stream.write(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Ttej-7Wua4",
        "colab_type": "text"
      },
      "source": [
        "**real text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqx3emDKV3Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aligned_fr = \"/content/drive/My Drive/ift6759/ift6759-t6-p2/data/aligned_formated_fr\"\n",
        "aligned_en = \"/content/drive/My Drive/ift6759/ift6759-t6-p2/data/aligned_unformated_en\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtJKdhhGkjEP",
        "colab_type": "text"
      },
      "source": [
        "**original unaligned**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-MFthyqkimk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_unaligned_fr = \"/content/drive/My Drive/ift6759/ift6759-t6-p2/data/unaligned_formated_fr\"\n",
        "original_unaligned_en = \"/content/drive/My Drive/ift6759/ift6759-t6-p2/data/unaligned_unformated_en\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPsVpMccWy1j",
        "colab_type": "text"
      },
      "source": [
        "**virtual text**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsO58qi5WLU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unaligned_fr = \"/content/drive/My Drive/ift6759/ift6759-t6-p2/data/cycle3/unaligned_formated_fr\"\n",
        "unaligned_en = \"/content/drive/My Drive/ift6759/ift6759-t6-p2/data/cycle3/unaligned_unformated_en\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOnNeQULW4NC",
        "colab_type": "text"
      },
      "source": [
        "**real dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLpPZX6_mevi",
        "colab_type": "code",
        "outputId": "cf269bb9-f87d-42f0-8fe3-e25af7e70920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_dataset, encoder_v2id, encoder_id2v = encoder_preprocess(data=aligned_en)\n",
        "decoder_dataset, decoder_v2id, decoder_id2v = decoder_preprocess(data=aligned_fr)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/11000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 2/11000 [00:01<1:39:48,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 77/11000 [00:01<1:09:27,  2.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 168/11000 [00:01<48:16,  3.74it/s] \u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 279/11000 [00:01<33:29,  5.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 421/11000 [00:01<23:10,  7.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 529/11000 [00:01<16:06, 10.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 660/11000 [00:01<11:10, 15.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 769/11000 [00:01<07:47, 21.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 878/11000 [00:01<05:26, 31.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 990/11000 [00:01<03:48, 43.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 1121/11000 [00:02<02:40, 61.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 1281/11000 [00:02<01:52, 86.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 1408/11000 [00:02<01:20, 118.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 1526/11000 [00:02<00:58, 162.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 1645/11000 [00:02<00:42, 218.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 1761/11000 [00:02<00:32, 286.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1879/11000 [00:02<00:24, 369.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 2002/11000 [00:02<00:19, 466.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 2117/11000 [00:02<00:15, 559.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 2255/11000 [00:03<00:12, 677.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 2386/11000 [00:03<00:10, 791.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 2508/11000 [00:03<00:09, 883.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 2630/11000 [00:03<00:08, 955.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 2756/11000 [00:03<00:08, 1028.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 2878/11000 [00:03<00:07, 1070.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 2999/11000 [00:03<00:07, 1088.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 3118/11000 [00:03<00:07, 1115.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 3250/11000 [00:03<00:06, 1167.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 3392/11000 [00:04<00:06, 1221.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 3519/11000 [00:04<00:06, 1185.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 3641/11000 [00:04<00:06, 1161.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 3771/11000 [00:04<00:06, 1191.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 3902/11000 [00:04<00:05, 1215.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 4025/11000 [00:04<00:05, 1186.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 4174/11000 [00:04<00:05, 1262.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 4307/11000 [00:04<00:05, 1278.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 4437/11000 [00:04<00:05, 1267.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 4587/11000 [00:04<00:04, 1327.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 4722/11000 [00:05<00:05, 1247.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 4854/11000 [00:05<00:04, 1263.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 4982/11000 [00:05<00:04, 1208.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 5105/11000 [00:05<00:05, 1169.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 5248/11000 [00:05<00:04, 1220.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 5379/11000 [00:05<00:04, 1245.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 5505/11000 [00:05<00:04, 1225.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 5645/11000 [00:05<00:04, 1265.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 5790/11000 [00:05<00:03, 1312.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 5923/11000 [00:06<00:03, 1302.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 6055/11000 [00:06<00:03, 1244.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 6181/11000 [00:06<00:03, 1212.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 6314/11000 [00:06<00:03, 1242.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 6440/11000 [00:06<00:04, 1117.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 6578/11000 [00:06<00:03, 1185.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 6700/11000 [00:06<00:03, 1152.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6818/11000 [00:06<00:03, 1051.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 6927/11000 [00:06<00:03, 1019.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 7043/11000 [00:07<00:03, 1056.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 7152/11000 [00:07<00:03, 1064.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 7265/11000 [00:07<00:03, 1082.57it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 7382/11000 [00:07<00:03, 1106.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 7515/11000 [00:07<00:03, 1158.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 7647/11000 [00:07<00:02, 1196.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 7796/11000 [00:07<00:02, 1261.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 7924/11000 [00:07<00:02, 1260.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 8052/11000 [00:07<00:02, 1152.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 8170/11000 [00:08<00:02, 1146.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 8287/11000 [00:08<00:02, 1124.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 8428/11000 [00:08<00:02, 1187.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 8565/11000 [00:08<00:01, 1227.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 8690/11000 [00:08<00:02, 1104.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 8805/11000 [00:08<00:02, 1067.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 8919/11000 [00:08<00:01, 1087.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 9060/11000 [00:08<00:01, 1166.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 9180/11000 [00:08<00:01, 1127.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 9300/11000 [00:08<00:01, 1133.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 9430/11000 [00:09<00:01, 1176.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 9550/11000 [00:09<00:01, 1130.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 9674/11000 [00:09<00:01, 1159.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 9799/11000 [00:09<00:01, 1181.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 9919/11000 [00:09<00:00, 1156.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 10036/11000 [00:09<00:00, 1136.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 10171/11000 [00:09<00:00, 1187.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 10303/11000 [00:09<00:00, 1219.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 10426/11000 [00:09<00:00, 1203.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 10548/11000 [00:10<00:00, 1087.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 10662/11000 [00:10<00:00, 1099.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 10782/11000 [00:10<00:00, 1121.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 11000/11000 [00:10<00:00, 1053.99it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/11000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1/11000 [00:01<5:05:07,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 21/11000 [00:01<3:33:30,  1.17s/it]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 37/11000 [00:01<2:29:35,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 60/11000 [00:01<1:44:44,  1.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 85/11000 [00:02<1:13:24,  2.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 107/11000 [00:02<51:32,  3.52it/s] \u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 126/11000 [00:02<36:18,  4.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|▏         | 153/11000 [00:02<25:33,  7.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 176/11000 [00:02<18:05,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 197/11000 [00:02<12:53, 13.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 218/11000 [00:02<09:16, 19.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 239/11000 [00:02<06:47, 26.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 259/11000 [00:02<05:01, 35.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 279/11000 [00:03<03:48, 46.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 299/11000 [00:03<03:10, 56.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 317/11000 [00:03<02:31, 70.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 339/11000 [00:03<02:00, 88.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 365/11000 [00:03<01:37, 109.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 390/11000 [00:03<01:21, 130.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 412/11000 [00:03<01:14, 142.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 433/11000 [00:03<01:13, 144.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 457/11000 [00:04<01:04, 163.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 481/11000 [00:04<00:58, 180.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 503/11000 [00:04<00:55, 189.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 526/11000 [00:04<00:52, 198.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 548/11000 [00:04<00:53, 196.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 570/11000 [00:04<00:51, 203.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 592/11000 [00:04<00:53, 195.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 613/11000 [00:04<00:54, 188.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 633/11000 [00:04<00:54, 190.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 653/11000 [00:05<01:05, 157.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 671/11000 [00:05<01:03, 162.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 691/11000 [00:05<01:00, 171.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 710/11000 [00:05<00:58, 175.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 731/11000 [00:05<00:56, 183.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 750/11000 [00:05<00:55, 184.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 772/11000 [00:05<00:53, 190.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 792/11000 [00:05<00:54, 186.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 812/11000 [00:05<00:53, 190.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 832/11000 [00:05<00:52, 192.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 857/11000 [00:06<00:49, 206.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 885/11000 [00:06<00:45, 223.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 909/11000 [00:06<00:45, 219.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 932/11000 [00:06<00:45, 222.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 955/11000 [00:06<00:49, 202.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 981/11000 [00:06<00:46, 216.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 1004/11000 [00:06<00:46, 213.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 1026/11000 [00:06<00:47, 208.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 1048/11000 [00:07<01:09, 142.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 1069/11000 [00:07<01:03, 156.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 1091/11000 [00:07<00:58, 170.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 1117/11000 [00:07<00:52, 186.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 1143/11000 [00:07<00:48, 201.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 1165/11000 [00:07<00:50, 193.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 1190/11000 [00:07<00:47, 205.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 1218/11000 [00:07<00:43, 223.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 1242/11000 [00:07<00:44, 221.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 1272/11000 [00:08<00:40, 239.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 1298/11000 [00:08<00:42, 229.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 1322/11000 [00:08<00:42, 226.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 1346/11000 [00:08<00:44, 217.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 1369/11000 [00:08<00:44, 215.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 1391/11000 [00:08<00:47, 201.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 1416/11000 [00:08<00:45, 212.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 1438/11000 [00:08<00:44, 213.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 1460/11000 [00:09<00:46, 206.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 1481/11000 [00:09<00:52, 181.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 1503/11000 [00:09<00:49, 191.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 1526/11000 [00:09<00:47, 201.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 1548/11000 [00:09<00:46, 203.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 1570/11000 [00:09<00:45, 206.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 1591/11000 [00:09<00:46, 202.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 1612/11000 [00:09<00:46, 204.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 1633/11000 [00:09<00:46, 203.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 1654/11000 [00:09<00:47, 197.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 1674/11000 [00:10<00:47, 197.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 1694/11000 [00:10<00:48, 191.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 1715/11000 [00:10<00:47, 193.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 1739/11000 [00:10<00:45, 204.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 1760/11000 [00:10<00:44, 205.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 1788/11000 [00:10<00:41, 223.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 1811/11000 [00:10<00:47, 193.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1835/11000 [00:10<00:45, 202.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1857/11000 [00:11<00:47, 194.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1878/11000 [00:11<00:47, 193.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1898/11000 [00:11<00:46, 194.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1918/11000 [00:11<00:46, 195.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 1945/11000 [00:11<00:42, 211.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 1970/11000 [00:11<00:41, 217.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 1993/11000 [00:11<00:41, 219.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 2016/11000 [00:11<00:44, 204.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 2042/11000 [00:11<00:41, 214.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 2071/11000 [00:11<00:38, 231.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 2095/11000 [00:12<00:40, 218.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 2118/11000 [00:12<00:40, 216.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 2147/11000 [00:12<00:38, 229.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 2171/11000 [00:12<00:38, 227.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 2195/11000 [00:12<00:38, 228.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 2219/11000 [00:12<00:38, 228.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 2242/11000 [00:12<00:40, 218.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 2265/11000 [00:12<00:40, 216.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 2294/11000 [00:12<00:37, 232.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 2318/11000 [00:13<00:37, 231.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 2342/11000 [00:13<00:39, 216.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 2365/11000 [00:13<00:41, 207.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 2387/11000 [00:13<00:41, 208.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 2409/11000 [00:13<00:42, 204.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 2434/11000 [00:13<00:39, 214.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 2459/11000 [00:13<00:38, 221.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 2482/11000 [00:13<00:39, 217.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 2504/11000 [00:13<00:40, 211.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 2527/11000 [00:14<00:39, 216.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 2549/11000 [00:14<00:39, 213.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 2572/11000 [00:14<00:38, 216.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▎       | 2594/11000 [00:14<00:39, 213.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 2618/11000 [00:14<00:38, 219.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 2641/11000 [00:14<00:38, 216.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 2665/11000 [00:14<00:37, 221.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 2689/11000 [00:14<00:36, 226.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 2712/11000 [00:14<00:37, 220.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 2735/11000 [00:14<00:37, 221.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 2758/11000 [00:15<00:37, 217.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 2780/11000 [00:15<00:41, 200.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 2803/11000 [00:15<00:39, 206.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 2824/11000 [00:15<00:42, 193.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 2845/11000 [00:15<00:41, 197.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 2874/11000 [00:15<00:37, 215.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 2897/11000 [00:15<00:37, 215.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 2920/11000 [00:15<00:37, 217.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 2948/11000 [00:15<00:34, 231.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 2972/11000 [00:16<00:34, 230.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 2996/11000 [00:16<00:36, 218.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 3022/11000 [00:16<00:35, 226.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 3046/11000 [00:16<00:34, 228.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 3070/11000 [00:16<00:35, 225.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 3093/11000 [00:16<00:35, 220.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 3117/11000 [00:16<00:34, 225.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 3140/11000 [00:16<00:36, 215.50it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 3163/11000 [00:16<00:36, 217.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 3187/11000 [00:17<00:35, 220.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 3210/11000 [00:17<00:37, 209.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 3238/11000 [00:17<00:34, 226.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 3262/11000 [00:17<00:34, 223.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 3285/11000 [00:17<00:34, 225.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 3312/11000 [00:17<00:32, 235.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 3336/11000 [00:17<00:34, 220.57it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 3362/11000 [00:17<00:33, 230.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 3386/11000 [00:17<00:32, 231.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 3414/11000 [00:18<00:31, 243.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 3439/11000 [00:18<00:32, 231.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 3463/11000 [00:18<00:34, 220.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 3488/11000 [00:18<00:33, 227.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 3513/11000 [00:18<00:32, 233.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 3537/11000 [00:18<00:34, 218.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 3565/11000 [00:18<00:31, 233.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 3589/11000 [00:18<00:33, 224.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 3617/11000 [00:18<00:31, 235.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 3641/11000 [00:19<00:32, 223.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 3669/11000 [00:19<00:31, 235.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 3696/11000 [00:19<00:30, 241.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 3722/11000 [00:19<00:29, 244.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 3747/11000 [00:19<00:30, 239.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 3772/11000 [00:19<00:32, 224.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 3796/11000 [00:19<00:31, 228.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 3820/11000 [00:19<00:31, 225.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 3845/11000 [00:19<00:30, 232.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 3869/11000 [00:20<00:31, 228.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 3892/11000 [00:20<00:31, 222.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 3919/11000 [00:20<00:30, 234.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 3943/11000 [00:20<00:30, 229.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 3970/11000 [00:20<00:29, 237.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 3994/11000 [00:20<00:31, 225.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 4017/11000 [00:20<00:32, 214.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 4041/11000 [00:20<00:31, 221.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 4064/11000 [00:20<00:32, 215.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 4087/11000 [00:20<00:31, 219.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 4113/11000 [00:21<00:30, 228.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 4137/11000 [00:21<00:29, 229.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 4162/11000 [00:21<00:29, 229.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 4186/11000 [00:21<00:30, 223.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 4209/11000 [00:21<00:30, 221.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 4234/11000 [00:21<00:29, 229.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 4262/11000 [00:21<00:27, 240.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 4287/11000 [00:21<00:29, 227.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 4311/11000 [00:21<00:32, 205.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 4334/11000 [00:22<00:31, 209.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 4358/11000 [00:22<00:30, 216.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 4385/11000 [00:22<00:28, 230.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 4409/11000 [00:22<00:30, 215.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 4432/11000 [00:22<00:30, 218.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 4459/11000 [00:22<00:28, 227.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 4483/11000 [00:22<00:28, 225.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 4506/11000 [00:22<00:28, 225.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 4530/11000 [00:22<00:28, 228.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 4554/11000 [00:23<00:28, 223.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 4581/11000 [00:23<00:27, 234.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 4606/11000 [00:23<00:26, 239.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 4631/11000 [00:23<00:30, 207.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 4653/11000 [00:23<00:31, 201.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▎     | 4675/11000 [00:23<00:30, 206.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 4697/11000 [00:23<00:30, 208.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 4719/11000 [00:23<00:30, 206.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 4740/11000 [00:23<00:30, 206.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 4761/11000 [00:24<00:30, 205.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 4785/11000 [00:24<00:29, 211.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 4809/11000 [00:24<00:28, 218.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 4831/11000 [00:24<00:30, 200.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 4852/11000 [00:24<00:30, 202.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 4873/11000 [00:24<00:30, 204.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 4899/11000 [00:24<00:27, 218.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 4922/11000 [00:24<00:27, 220.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 4945/11000 [00:24<00:27, 220.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 4970/11000 [00:25<00:26, 228.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 4994/11000 [00:25<00:27, 220.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 5017/11000 [00:25<00:28, 212.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 5040/11000 [00:25<00:27, 216.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 5063/11000 [00:25<00:26, 219.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 5086/11000 [00:25<00:26, 219.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 5120/11000 [00:25<00:24, 242.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 5146/11000 [00:25<00:23, 246.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 5172/11000 [00:25<00:25, 232.50it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 5196/11000 [00:26<00:26, 220.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 5224/11000 [00:26<00:24, 235.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 5249/11000 [00:26<00:24, 234.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 5276/11000 [00:26<00:23, 243.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 5301/11000 [00:26<00:26, 211.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 5326/11000 [00:26<00:25, 221.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 5355/11000 [00:26<00:23, 237.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 5380/11000 [00:26<00:23, 236.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 5405/11000 [00:26<00:23, 240.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 5430/11000 [00:26<00:23, 234.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 5454/11000 [00:27<00:24, 228.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 5478/11000 [00:27<00:25, 220.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 5501/11000 [00:27<00:24, 222.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 5524/11000 [00:27<00:24, 223.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 5547/11000 [00:27<00:24, 223.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 5570/11000 [00:27<00:24, 224.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 5596/11000 [00:27<00:23, 233.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 5624/11000 [00:27<00:21, 244.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 5649/11000 [00:27<00:23, 231.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 5673/11000 [00:28<00:23, 227.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 5698/11000 [00:28<00:23, 229.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 5723/11000 [00:28<00:22, 234.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 5747/11000 [00:28<00:22, 232.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 5779/11000 [00:28<00:21, 246.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 5804/11000 [00:28<00:22, 233.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 5830/11000 [00:28<00:21, 240.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 5855/11000 [00:28<00:23, 222.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 5882/11000 [00:28<00:21, 234.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 5906/11000 [00:29<00:21, 235.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 5930/11000 [00:29<00:21, 232.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 5954/11000 [00:29<00:22, 221.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 5977/11000 [00:29<00:22, 223.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 6001/11000 [00:29<00:21, 227.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 6024/11000 [00:29<00:24, 205.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 6046/11000 [00:29<00:23, 207.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 6070/11000 [00:29<00:23, 213.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 6092/11000 [00:29<00:23, 210.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 6114/11000 [00:30<00:24, 197.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 6135/11000 [00:30<00:24, 199.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 6161/11000 [00:30<00:22, 210.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 6183/11000 [00:30<00:23, 202.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 6211/11000 [00:30<00:21, 218.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 6234/11000 [00:30<00:21, 221.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 6258/11000 [00:30<00:21, 223.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 6281/11000 [00:30<00:21, 224.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 6305/11000 [00:30<00:20, 226.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 6329/11000 [00:31<00:20, 224.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 6352/11000 [00:31<00:21, 219.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 6375/11000 [00:31<00:21, 214.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 6397/11000 [00:31<00:21, 210.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 6419/11000 [00:31<00:22, 207.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 6450/11000 [00:31<00:19, 228.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 6474/11000 [00:31<00:22, 200.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 6496/11000 [00:31<00:23, 195.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 6522/11000 [00:31<00:21, 208.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 6546/11000 [00:32<00:20, 216.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 6569/11000 [00:32<00:21, 205.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 6595/11000 [00:32<00:20, 216.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 6618/11000 [00:32<00:20, 218.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 6641/11000 [00:32<00:19, 220.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 6664/11000 [00:32<00:19, 216.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 6686/11000 [00:32<00:22, 193.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 6706/11000 [00:32<00:22, 192.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 6728/11000 [00:32<00:21, 196.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 6748/11000 [00:33<00:22, 192.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6769/11000 [00:33<00:21, 196.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6790/11000 [00:33<00:21, 199.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6811/11000 [00:33<00:21, 198.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6831/11000 [00:33<00:22, 183.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6853/11000 [00:33<00:21, 192.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 6873/11000 [00:33<00:22, 186.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 6899/11000 [00:33<00:20, 201.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 6921/11000 [00:33<00:19, 205.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 6942/11000 [00:34<00:19, 203.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 6970/11000 [00:34<00:18, 221.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▎   | 6993/11000 [00:34<00:18, 215.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 7015/11000 [00:34<00:18, 210.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 7039/11000 [00:34<00:19, 206.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 7060/11000 [00:34<00:19, 204.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 7081/11000 [00:34<00:19, 201.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 7102/11000 [00:34<00:19, 201.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 7123/11000 [00:34<00:19, 196.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 7143/11000 [00:34<00:19, 195.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 7164/11000 [00:35<00:19, 196.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 7189/11000 [00:35<00:18, 209.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 7211/11000 [00:35<00:18, 205.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 7232/11000 [00:35<00:18, 205.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 7258/11000 [00:35<00:17, 216.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 7280/11000 [00:35<00:17, 213.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 7302/11000 [00:35<00:17, 214.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 7324/11000 [00:35<00:17, 213.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 7346/11000 [00:35<00:17, 210.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 7368/11000 [00:36<00:17, 209.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 7391/11000 [00:36<00:16, 213.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 7417/11000 [00:36<00:15, 224.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 7444/11000 [00:36<00:15, 234.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 7470/11000 [00:36<00:14, 240.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 7495/11000 [00:36<00:15, 232.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 7520/11000 [00:36<00:14, 237.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 7544/11000 [00:36<00:15, 224.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 7569/11000 [00:36<00:14, 230.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 7594/11000 [00:36<00:14, 233.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 7618/11000 [00:37<00:14, 232.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 7642/11000 [00:37<00:15, 221.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 7665/11000 [00:37<00:15, 211.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 7687/11000 [00:37<00:15, 209.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 7713/11000 [00:37<00:14, 220.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 7742/11000 [00:37<00:13, 235.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 7766/11000 [00:37<00:14, 216.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 7789/11000 [00:37<00:14, 215.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 7811/11000 [00:38<00:15, 204.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 7834/11000 [00:38<00:15, 209.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 7859/11000 [00:38<00:14, 216.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 7884/11000 [00:38<00:13, 224.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 7907/11000 [00:38<00:13, 222.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 7930/11000 [00:38<00:14, 209.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 7952/11000 [00:38<00:15, 202.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 7973/11000 [00:38<00:16, 183.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 7992/11000 [00:38<00:16, 179.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 8018/11000 [00:39<00:15, 196.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 8039/11000 [00:39<00:15, 196.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 8062/11000 [00:39<00:14, 203.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 8083/11000 [00:39<00:14, 196.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 8105/11000 [00:39<00:14, 201.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 8129/11000 [00:39<00:13, 209.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 8151/11000 [00:39<00:13, 212.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 8174/11000 [00:39<00:13, 216.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 8196/11000 [00:39<00:14, 194.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 8216/11000 [00:40<00:14, 189.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 8244/11000 [00:40<00:13, 207.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 8272/11000 [00:40<00:12, 222.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 8296/11000 [00:40<00:12, 223.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 8320/11000 [00:40<00:11, 227.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 8344/11000 [00:40<00:11, 227.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 8368/11000 [00:40<00:11, 227.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▋  | 8394/11000 [00:40<00:11, 236.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 8418/11000 [00:40<00:11, 231.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 8442/11000 [00:40<00:11, 230.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 8466/11000 [00:41<00:11, 221.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 8489/11000 [00:41<00:11, 223.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 8513/11000 [00:41<00:10, 227.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 8538/11000 [00:41<00:10, 233.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 8562/11000 [00:41<00:11, 215.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 8587/11000 [00:41<00:10, 220.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 8610/11000 [00:41<00:11, 206.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 8632/11000 [00:41<00:12, 194.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 8652/11000 [00:41<00:12, 190.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 8672/11000 [00:42<00:12, 183.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 8693/11000 [00:42<00:12, 189.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 8713/11000 [00:42<00:12, 178.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 8736/11000 [00:42<00:11, 189.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 8756/11000 [00:42<00:11, 192.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 8780/11000 [00:42<00:10, 204.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 8801/11000 [00:42<00:11, 196.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 8822/11000 [00:42<00:11, 189.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 8842/11000 [00:42<00:11, 188.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 8863/11000 [00:43<00:11, 191.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 8885/11000 [00:43<00:10, 197.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 8905/11000 [00:43<00:10, 194.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 8925/11000 [00:43<00:11, 187.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 8951/11000 [00:43<00:10, 203.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 8979/11000 [00:43<00:09, 221.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 9002/11000 [00:43<00:09, 207.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 9024/11000 [00:43<00:09, 209.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 9046/11000 [00:43<00:09, 203.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 9071/11000 [00:44<00:09, 211.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 9094/11000 [00:44<00:08, 215.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 9117/11000 [00:44<00:08, 218.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 9140/11000 [00:44<00:08, 213.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 9162/11000 [00:44<00:09, 202.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 9185/11000 [00:44<00:08, 209.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 9208/11000 [00:44<00:08, 213.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 9230/11000 [00:44<00:08, 209.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 9253/11000 [00:44<00:08, 213.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 9276/11000 [00:45<00:07, 216.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 9298/11000 [00:45<00:08, 208.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 9320/11000 [00:45<00:07, 210.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 9342/11000 [00:45<00:08, 206.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 9363/11000 [00:45<00:08, 202.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 9384/11000 [00:45<00:08, 196.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 9406/11000 [00:45<00:07, 201.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 9432/11000 [00:45<00:07, 214.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 9458/11000 [00:45<00:06, 225.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 9481/11000 [00:45<00:07, 211.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 9503/11000 [00:46<00:07, 211.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 9529/11000 [00:46<00:06, 222.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 9552/11000 [00:46<00:06, 220.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 9575/11000 [00:46<00:06, 218.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 9600/11000 [00:46<00:06, 225.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 9623/11000 [00:46<00:06, 218.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 9646/11000 [00:46<00:06, 207.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 9673/11000 [00:46<00:05, 222.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 9698/11000 [00:46<00:05, 217.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 9722/11000 [00:47<00:05, 222.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 9745/11000 [00:47<00:05, 218.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 9773/11000 [00:47<00:05, 232.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 9797/11000 [00:47<00:05, 233.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 9821/11000 [00:47<00:05, 233.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 9847/11000 [00:47<00:04, 240.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 9872/11000 [00:47<00:04, 237.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 9899/11000 [00:47<00:04, 244.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 9925/11000 [00:47<00:04, 247.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 9950/11000 [00:48<00:04, 215.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 9975/11000 [00:48<00:04, 222.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 9998/11000 [00:48<00:04, 205.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 10023/11000 [00:48<00:04, 212.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 10045/11000 [00:48<00:04, 213.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 10067/11000 [00:48<00:04, 199.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 10088/11000 [00:48<00:04, 202.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 10109/11000 [00:48<00:04, 202.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 10133/11000 [00:48<00:04, 207.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 10154/11000 [00:49<00:04, 200.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 10176/11000 [00:49<00:04, 203.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 10203/11000 [00:49<00:03, 218.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 10229/11000 [00:49<00:03, 227.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 10253/11000 [00:49<00:03, 202.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 10275/11000 [00:49<00:03, 206.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 10301/11000 [00:49<00:03, 217.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 10324/11000 [00:49<00:03, 211.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 10346/11000 [00:49<00:03, 203.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 10367/11000 [00:50<00:03, 200.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 10388/11000 [00:50<00:03, 193.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 10408/11000 [00:50<00:03, 179.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 10430/11000 [00:50<00:03, 186.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 10453/11000 [00:50<00:02, 197.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 10477/11000 [00:50<00:02, 207.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 10503/11000 [00:50<00:02, 208.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 10525/11000 [00:50<00:02, 187.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 10550/11000 [00:50<00:02, 200.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 10571/11000 [00:51<00:02, 192.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 10593/11000 [00:51<00:02, 198.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 10614/11000 [00:51<00:02, 191.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 10639/11000 [00:51<00:01, 202.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 10660/11000 [00:51<00:01, 198.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 10681/11000 [00:51<00:01, 198.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 10704/11000 [00:51<00:01, 206.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 10726/11000 [00:51<00:01, 207.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 10752/11000 [00:51<00:01, 219.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 10775/11000 [00:52<00:01, 218.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 10798/11000 [00:52<00:00, 212.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 10824/11000 [00:52<00:00, 224.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 10847/11000 [00:52<00:00, 223.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 10870/11000 [00:52<00:00, 218.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 10893/11000 [00:52<00:00, 199.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 10914/11000 [00:52<00:00, 198.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 10937/11000 [00:52<00:00, 204.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 10958/11000 [00:52<00:00, 197.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 11000/11000 [00:53<00:00, 206.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOzFMywhXAUK",
        "colab_type": "text"
      },
      "source": [
        "**virtual dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36_cgFMKXCX-",
        "colab_type": "code",
        "outputId": "57d90dbf-6b7a-482a-dc9b-74f23290d0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_dataset, encoder_v2id, encoder_id2v = encoder_preprocess(data=unaligned_en)\n",
        "decoder_dataset, decoder_v2id, decoder_id2v = decoder_preprocess(data=unaligned_fr)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/25600 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 2/25600 [00:01<3:51:16,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 103/25600 [00:01<2:41:22,  2.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 208/25600 [00:01<1:52:37,  3.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 310/25600 [00:01<1:18:38,  5.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 424/25600 [00:01<54:55,  7.64it/s]  \u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 569/25600 [00:01<38:18, 10.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 682/25600 [00:01<26:48, 15.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 785/25600 [00:01<18:48, 21.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 902/25600 [00:01<13:12, 31.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 1008/25600 [00:02<09:20, 43.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 1112/25600 [00:02<06:37, 61.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 1241/25600 [00:02<04:42, 86.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 1352/25600 [00:02<03:23, 118.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 1482/25600 [00:02<02:27, 163.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 1624/25600 [00:02<01:47, 222.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 1747/25600 [00:02<01:21, 294.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 1878/25600 [00:02<01:01, 383.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 2002/25600 [00:02<00:49, 478.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 2124/25600 [00:02<00:40, 581.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 2244/25600 [00:03<00:34, 685.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 2390/25600 [00:03<00:28, 813.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 2517/25600 [00:03<00:25, 911.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 2647/25600 [00:03<00:22, 1000.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 2775/25600 [00:03<00:21, 1058.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 2930/25600 [00:03<00:19, 1163.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 3064/25600 [00:03<00:18, 1203.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 3197/25600 [00:03<00:19, 1141.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 3337/25600 [00:03<00:18, 1207.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 3466/25600 [00:03<00:18, 1193.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 3591/25600 [00:04<00:18, 1192.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 3734/25600 [00:04<00:17, 1243.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 3862/25600 [00:04<00:18, 1193.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 3985/25600 [00:04<00:18, 1148.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 4130/25600 [00:04<00:17, 1218.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 4255/25600 [00:04<00:17, 1196.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 4377/25600 [00:04<00:17, 1186.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 4538/25600 [00:04<00:16, 1276.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 4669/25600 [00:05<00:18, 1129.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 4788/25600 [00:05<00:18, 1134.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 4932/25600 [00:05<00:17, 1209.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 5060/25600 [00:05<00:16, 1223.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 5199/25600 [00:05<00:16, 1262.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 5345/25600 [00:05<00:15, 1311.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 5510/25600 [00:05<00:14, 1396.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 5653/25600 [00:05<00:15, 1314.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 5788/25600 [00:05<00:15, 1259.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 5917/25600 [00:05<00:16, 1195.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▎       | 6059/25600 [00:06<00:15, 1248.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 6187/25600 [00:06<00:15, 1224.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 6312/25600 [00:06<00:15, 1212.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 6435/25600 [00:06<00:15, 1216.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 6558/25600 [00:06<00:15, 1199.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 6679/25600 [00:06<00:16, 1173.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 6817/25600 [00:06<00:15, 1227.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 6941/25600 [00:06<00:15, 1199.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 7062/25600 [00:06<00:15, 1160.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 7179/25600 [00:07<00:16, 1147.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 7305/25600 [00:07<00:15, 1178.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 7425/25600 [00:07<00:15, 1182.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 7570/25600 [00:07<00:14, 1249.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 7697/25600 [00:07<00:15, 1164.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 7838/25600 [00:07<00:14, 1224.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 7974/25600 [00:07<00:13, 1261.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 8103/25600 [00:07<00:14, 1213.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 8227/25600 [00:07<00:14, 1193.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 8348/25600 [00:07<00:14, 1158.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 8465/25600 [00:08<00:14, 1143.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 8581/25600 [00:08<00:15, 1104.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 8710/25600 [00:08<00:14, 1143.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 8858/25600 [00:08<00:13, 1223.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 9001/25600 [00:08<00:12, 1278.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 9138/25600 [00:08<00:12, 1299.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 9270/25600 [00:08<00:12, 1260.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 9398/25600 [00:08<00:13, 1222.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 9543/25600 [00:08<00:12, 1275.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 9673/25600 [00:09<00:12, 1246.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 9799/25600 [00:09<00:13, 1197.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 9921/25600 [00:09<00:13, 1189.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 10041/25600 [00:09<00:13, 1185.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 10162/25600 [00:09<00:13, 1180.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 10281/25600 [00:09<00:13, 1156.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 10398/25600 [00:09<00:13, 1111.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 10510/25600 [00:09<00:15, 1002.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 10613/25600 [00:09<00:14, 1001.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 10748/25600 [00:10<00:13, 1085.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 10860/25600 [00:10<00:14, 1042.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 11002/25600 [00:10<00:12, 1132.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 11130/25600 [00:10<00:12, 1162.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 11261/25600 [00:10<00:11, 1201.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 11384/25600 [00:10<00:12, 1160.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 11503/25600 [00:10<00:12, 1144.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 11635/25600 [00:10<00:11, 1189.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 11756/25600 [00:10<00:12, 1104.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 11869/25600 [00:11<00:12, 1101.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 11981/25600 [00:11<00:12, 1091.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 12135/25600 [00:11<00:11, 1193.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 12258/25600 [00:11<00:11, 1166.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 12390/25600 [00:11<00:11, 1200.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 12531/25600 [00:11<00:10, 1254.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 12693/25600 [00:11<00:09, 1339.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 12855/25600 [00:11<00:09, 1412.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 13000/25600 [00:11<00:09, 1345.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 13138/25600 [00:11<00:09, 1291.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 13280/25600 [00:12<00:09, 1326.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 13415/25600 [00:12<00:09, 1242.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 13562/25600 [00:12<00:09, 1302.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 13722/25600 [00:12<00:08, 1367.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 13862/25600 [00:12<00:08, 1332.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 13998/25600 [00:12<00:08, 1305.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 14131/25600 [00:12<00:09, 1208.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 14285/25600 [00:12<00:08, 1287.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 14417/25600 [00:12<00:08, 1288.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 14549/25600 [00:13<00:08, 1260.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 14677/25600 [00:13<00:08, 1214.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 14808/25600 [00:13<00:08, 1238.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 14934/25600 [00:13<00:08, 1209.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 15072/25600 [00:13<00:08, 1247.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 15198/25600 [00:13<00:08, 1215.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 15330/25600 [00:13<00:08, 1242.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 15456/25600 [00:13<00:08, 1183.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 15582/25600 [00:13<00:08, 1202.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 15704/25600 [00:14<00:08, 1205.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 15830/25600 [00:14<00:08, 1220.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 15953/25600 [00:14<00:08, 1121.50it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 16070/25600 [00:14<00:08, 1130.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 16206/25600 [00:14<00:07, 1185.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 16327/25600 [00:14<00:07, 1171.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 16446/25600 [00:14<00:07, 1172.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 16579/25600 [00:14<00:07, 1211.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 16702/25600 [00:14<00:07, 1180.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 16834/25600 [00:14<00:07, 1218.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 16968/25600 [00:15<00:06, 1249.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 17106/25600 [00:15<00:06, 1285.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 17236/25600 [00:15<00:07, 1134.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 17354/25600 [00:15<00:07, 1115.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 17492/25600 [00:15<00:06, 1181.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 17621/25600 [00:15<00:06, 1212.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 17754/25600 [00:15<00:06, 1245.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 17881/25600 [00:15<00:06, 1235.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 18017/25600 [00:15<00:05, 1267.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 18161/25600 [00:16<00:05, 1306.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 18293/25600 [00:16<00:05, 1227.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 18436/25600 [00:16<00:05, 1279.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 18566/25600 [00:16<00:06, 1157.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 18695/25600 [00:16<00:05, 1187.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 18817/25600 [00:16<00:05, 1175.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 18960/25600 [00:16<00:05, 1240.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 19087/25600 [00:16<00:05, 1239.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 19217/25600 [00:16<00:05, 1253.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 19357/25600 [00:17<00:04, 1268.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 19485/25600 [00:17<00:05, 1219.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 19616/25600 [00:17<00:04, 1243.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 19742/25600 [00:17<00:04, 1236.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 19868/25600 [00:17<00:04, 1240.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 20041/25600 [00:17<00:04, 1355.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 20180/25600 [00:17<00:04, 1259.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 20324/25600 [00:17<00:04, 1302.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 20458/25600 [00:17<00:03, 1301.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 20591/25600 [00:17<00:03, 1280.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 20747/25600 [00:18<00:03, 1343.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 20884/25600 [00:18<00:03, 1281.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 21015/25600 [00:18<00:03, 1221.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 21140/25600 [00:18<00:03, 1193.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 21261/25600 [00:18<00:03, 1148.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 21379/25600 [00:18<00:03, 1153.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 21536/25600 [00:18<00:03, 1249.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 21677/25600 [00:18<00:03, 1291.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 21809/25600 [00:18<00:03, 1252.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 21937/25600 [00:19<00:02, 1236.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 22089/25600 [00:19<00:02, 1307.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 22235/25600 [00:19<00:02, 1341.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 22371/25600 [00:19<00:02, 1254.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 22499/25600 [00:19<00:02, 1235.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 22625/25600 [00:19<00:02, 1238.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 22759/25600 [00:19<00:02, 1260.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 22886/25600 [00:19<00:02, 1189.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 23023/25600 [00:19<00:02, 1235.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 23148/25600 [00:20<00:01, 1229.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 23273/25600 [00:20<00:01, 1210.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 23395/25600 [00:20<00:01, 1172.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 23514/25600 [00:20<00:01, 1114.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 23631/25600 [00:20<00:01, 1128.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 23772/25600 [00:20<00:01, 1195.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 23901/25600 [00:20<00:01, 1221.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 24025/25600 [00:20<00:01, 1215.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 24148/25600 [00:20<00:01, 1212.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 24283/25600 [00:20<00:01, 1246.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 24409/25600 [00:21<00:01, 1155.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 24530/25600 [00:21<00:00, 1165.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 24648/25600 [00:21<00:00, 1142.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 24764/25600 [00:21<00:00, 1106.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 24876/25600 [00:21<00:00, 1099.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 24988/25600 [00:21<00:00, 1102.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 25102/25600 [00:21<00:00, 1113.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 25218/25600 [00:21<00:00, 1123.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 25331/25600 [00:21<00:00, 1074.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 25600/25600 [00:22<00:00, 1155.97it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/25600 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 4113/25600 [00:01<00:09, 2370.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 9670/25600 [00:01<00:04, 3325.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 15046/25600 [00:01<00:02, 4627.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 25600/25600 [00:02<00:00, 12047.33it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnXJ0hwbXV2d",
        "colab_type": "text"
      },
      "source": [
        "#### Split Train-Valid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5O3Lg1XKNia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(\n",
        "    input_tensor_train,\n",
        "    input_tensor_valid,\n",
        "    target_tensor_train,\n",
        "    target_tensor_valid\n",
        ") = train_test_split(encoder_dataset, decoder_dataset, test_size=0.2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkYCU30nONMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "batch_size = 32\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices(\n",
        "    (input_tensor_train, target_tensor_train)).batch(batch_size, drop_remainder=False)\n",
        "dataset_valid = tf.data.Dataset.from_tensor_slices(\n",
        "    (input_tensor_valid, target_tensor_valid)).batch(batch_size, drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9-BgT6v_wyc",
        "colab_type": "text"
      },
      "source": [
        "#### View data sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otUIR4qqKp2W",
        "colab_type": "code",
        "outputId": "4b65ed1d-d20c-4d35-81c4-a90148464bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "for i,j in dataset_train:\n",
        "  for z in i[10].numpy():\n",
        "    print(encoder_id2v[z], end = ' ')\n",
        "  print(\"\\n\")\n",
        "  for z in j[10].numpy():\n",
        "    print(decoder_id2v[z], end = ' ')\n",
        "  print(\"\\n\")\n",
        "  break\n",
        "\n",
        "for i,j in dataset_valid:\n",
        "  for z in i[0].numpy():\n",
        "    print(encoder_id2v[z], end = ' ')\n",
        "  print(\"\\n\")\n",
        "  for z in j[0].numpy():\n",
        "    print(decoder_id2v[z], end = ' ')\n",
        "  print(\"\\n\")\n",
        "  break\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SOS> regulation applying a scheme of generalised tariff preferences vote <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
            "\n",
            "<SOS> <CAP> règlement appliquant un schéma de préférences tarifaires généralisées <UNK> vote <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
            "\n",
            "<SOS> my wish is for you to help a strong sustainable movement to educate every child about food to inspire families to cook again and to empower people everywhere to fight obesity <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
            "\n",
            "<SOS> <CAP> mon souhait est que vous <UNK> un puissant mouvement durable pour éduquer chaque enfant à l <UNK> alimentation <UNK> pour inspirer les familles à cuisiner à nouveau <UNK> et dynamiser les gens partout à lutter contre l <UNK> obésité <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Transformer model for language understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BSiBsXrV-oIa"
      },
      "source": [
        "## Positional encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIOZjMNKujn",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rz82wEs5biZ",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2i8-e1s8ti9",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVxS8OPI9uI0",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LazzUq3bJ5SH",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n90YjClyInFy",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSV3PPKsYecw",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ET7xLt0yCT6Z",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncyS-Ms3i2x_",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9SoX0-vd1hue",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpEox7gJ8FCI",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5_d5-PLQXwY",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PED3bIpOYkBu",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnJn5SLA2ahP",
        "colab": {}
      },
      "source": [
        "num_layers = 2\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 16\n",
        "\n",
        "input_vocab_size = len(encoder_v2id) + 1\n",
        "target_vocab_size = len(decoder_v2id) + 1\n",
        "dropout_rate = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYQdOO1axwEI",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r4scdulztRx",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f33ZCgvHpPdG",
        "outputId": "325183d1-2b6c-4311-b080-6e73dde414d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlhsJMm0TW_B",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67oqVHiT0Eiu",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "phlyxMnm-Tpx",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='valid_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiysUa--4tOU",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOJUSB1T8GjM",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a78VOJjmfEDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt_path = \"./checkpoints/w2w/unformated_en_2_formated_fr/cycle3\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSPCgtpceZdK",
        "colab_type": "text"
      },
      "source": [
        "**real ckpt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNhuYfllndLZ",
        "colab": {}
      },
      "source": [
        "checkpoint_path = ckpt_path + \"/ckpt_real\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcVfqgaZeXCL",
        "colab_type": "text"
      },
      "source": [
        "**virtual ckpt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpNV7qteVGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = ckpt_path + \"/ckpt_virtual\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLMCL56X7_n3",
        "colab_type": "text"
      },
      "source": [
        "**Restore Ckpt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wrdQau7Basv",
        "colab_type": "code",
        "outputId": "f632fb36-9f62-4316-edd5-fc9db95196e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJwmp9OE29oj",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def valid_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  predictions, _ = transformer(inp, tar_inp, \n",
        "                                True, \n",
        "                                enc_padding_mask, \n",
        "                                combined_mask, \n",
        "                                dec_padding_mask)\n",
        "  loss = loss_function(tar_real, predictions)\n",
        "  valid_loss(loss)\n",
        "  valid_accuracy(tar_real, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnvwR9tZYz7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 27"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbvmaKNiznHZ",
        "outputId": "2388977c-bde0-4943-bdd9-a3e5da61244e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "576a72a5a25a4718a02cd9f3115763c0",
            "6b2f77ceaa5e4ea1a0c026ef94a5545d",
            "c864fe5e282d465ab4d52201bc467708",
            "9aa2e3fb54b34c499b0431d1a05193ea",
            "6ea849e1fc4c4d878d77c1c0b9074df2",
            "9949c5b9b2c3418e98c83925a8e4e238",
            "d67aa9ddd62c4ed4bcdf0afa48bf9335",
            "956330d18a344b9eb3a69e49fdb7c99d"
          ]
        }
      },
      "source": [
        "D={'T_loss':[], 'V_loss':[], 'T_Acc':[], 'V_Acc':[], 'E':[]}\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  valid_loss.reset_states()\n",
        "  valid_accuracy.reset_states()\n",
        "  \n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(dataset_train):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 100 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  for (batch, (v_inp, v_tar)) in enumerate(dataset_valid):\n",
        "    valid_step(v_inp, v_tar)\n",
        "\n",
        "  print ('Vaildation Epoch {} Val_Loss {:.4f}, Val_Acc {:.4f}'.format(\n",
        "          epoch + 1, valid_loss.result(), valid_accuracy.result()))\n",
        "  \n",
        "  D['T_loss'].append(train_loss.result().numpy())\n",
        "  D['V_loss'].append(valid_loss.result().numpy())\n",
        "  D['T_Acc'].append(train_accuracy.result().numpy())\n",
        "  D['V_Acc'].append(valid_accuracy.result().numpy())\n",
        "  D['E'].append(epoch + 1)\n",
        "\n",
        "\n",
        "  if (epoch + 1) % 1 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "576a72a5a25a4718a02cd9f3115763c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 6.4520 Accuracy 0.0643\n",
            "Epoch 1 Batch 100 Loss 4.1180 Accuracy 0.0769\n",
            "Epoch 1 Batch 200 Loss 3.8102 Accuracy 0.0796\n",
            "Vaildation Epoch 1 Val_Loss 4.0898, Val_Acc 0.0770\n",
            "Saving checkpoint for epoch 1 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-28\n",
            "Epoch 1 Loss 3.6398 Accuracy 0.0819\n",
            "Time taken for 1 epoch: 58.98204851150513 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 3.0654 Accuracy 0.0894\n",
            "Epoch 2 Batch 100 Loss 2.9969 Accuracy 0.0903\n",
            "Epoch 2 Batch 200 Loss 2.9638 Accuracy 0.0896\n",
            "Vaildation Epoch 2 Val_Loss 3.9353, Val_Acc 0.0787\n",
            "Saving checkpoint for epoch 2 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-29\n",
            "Epoch 2 Loss 2.9109 Accuracy 0.0906\n",
            "Time taken for 1 epoch: 46.96361780166626 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.8028 Accuracy 0.0965\n",
            "Epoch 3 Batch 100 Loss 2.7101 Accuracy 0.0943\n",
            "Epoch 3 Batch 200 Loss 2.6721 Accuracy 0.0936\n",
            "Vaildation Epoch 3 Val_Loss 3.8828, Val_Acc 0.0796\n",
            "Saving checkpoint for epoch 3 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-30\n",
            "Epoch 3 Loss 2.6307 Accuracy 0.0946\n",
            "Time taken for 1 epoch: 47.022231101989746 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.5784 Accuracy 0.1005\n",
            "Epoch 4 Batch 100 Loss 2.4921 Accuracy 0.0982\n",
            "Epoch 4 Batch 200 Loss 2.4603 Accuracy 0.0972\n",
            "Vaildation Epoch 4 Val_Loss 3.8644, Val_Acc 0.0801\n",
            "Saving checkpoint for epoch 4 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-31\n",
            "Epoch 4 Loss 2.4265 Accuracy 0.0980\n",
            "Time taken for 1 epoch: 46.83323311805725 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.3823 Accuracy 0.1010\n",
            "Epoch 5 Batch 100 Loss 2.3179 Accuracy 0.1011\n",
            "Epoch 5 Batch 200 Loss 2.2898 Accuracy 0.1001\n",
            "Vaildation Epoch 5 Val_Loss 3.8857, Val_Acc 0.0799\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-32\n",
            "Epoch 5 Loss 2.2633 Accuracy 0.1008\n",
            "Time taken for 1 epoch: 46.860692262649536 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.2149 Accuracy 0.1046\n",
            "Epoch 6 Batch 100 Loss 2.1776 Accuracy 0.1035\n",
            "Epoch 6 Batch 200 Loss 2.1558 Accuracy 0.1024\n",
            "Vaildation Epoch 6 Val_Loss 3.9104, Val_Acc 0.0800\n",
            "Saving checkpoint for epoch 6 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-33\n",
            "Epoch 6 Loss 2.1336 Accuracy 0.1032\n",
            "Time taken for 1 epoch: 46.89971303939819 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 2.0159 Accuracy 0.1085\n",
            "Epoch 7 Batch 100 Loss 2.0534 Accuracy 0.1063\n",
            "Epoch 7 Batch 200 Loss 2.0366 Accuracy 0.1050\n",
            "Vaildation Epoch 7 Val_Loss 3.9380, Val_Acc 0.0793\n",
            "Saving checkpoint for epoch 7 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-34\n",
            "Epoch 7 Loss 2.0196 Accuracy 0.1056\n",
            "Time taken for 1 epoch: 46.91360902786255 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.9906 Accuracy 0.1112\n",
            "Epoch 8 Batch 100 Loss 1.9522 Accuracy 0.1085\n",
            "Epoch 8 Batch 200 Loss 1.9356 Accuracy 0.1073\n",
            "Vaildation Epoch 8 Val_Loss 3.9593, Val_Acc 0.0803\n",
            "Saving checkpoint for epoch 8 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-35\n",
            "Epoch 8 Loss 1.9218 Accuracy 0.1079\n",
            "Time taken for 1 epoch: 46.89492678642273 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.9107 Accuracy 0.1121\n",
            "Epoch 9 Batch 100 Loss 1.8687 Accuracy 0.1109\n",
            "Epoch 9 Batch 200 Loss 1.8522 Accuracy 0.1095\n",
            "Vaildation Epoch 9 Val_Loss 3.9730, Val_Acc 0.0807\n",
            "Saving checkpoint for epoch 9 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-36\n",
            "Epoch 9 Loss 1.8404 Accuracy 0.1101\n",
            "Time taken for 1 epoch: 46.74940609931946 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.8474 Accuracy 0.1125\n",
            "Epoch 10 Batch 100 Loss 1.7828 Accuracy 0.1138\n",
            "Epoch 10 Batch 200 Loss 1.7725 Accuracy 0.1121\n",
            "Vaildation Epoch 10 Val_Loss 4.0010, Val_Acc 0.0803\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-37\n",
            "Epoch 10 Loss 1.7639 Accuracy 0.1126\n",
            "Time taken for 1 epoch: 46.819082736968994 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.7178 Accuracy 0.1148\n",
            "Epoch 11 Batch 100 Loss 1.7190 Accuracy 0.1158\n",
            "Epoch 11 Batch 200 Loss 1.7123 Accuracy 0.1141\n",
            "Vaildation Epoch 11 Val_Loss 4.0345, Val_Acc 0.0800\n",
            "Saving checkpoint for epoch 11 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-38\n",
            "Epoch 11 Loss 1.7034 Accuracy 0.1144\n",
            "Time taken for 1 epoch: 46.73088526725769 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.6251 Accuracy 0.1193\n",
            "Epoch 12 Batch 100 Loss 1.6492 Accuracy 0.1184\n",
            "Epoch 12 Batch 200 Loss 1.6484 Accuracy 0.1162\n",
            "Vaildation Epoch 12 Val_Loss 4.0678, Val_Acc 0.0798\n",
            "Saving checkpoint for epoch 12 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-39\n",
            "Epoch 12 Loss 1.6417 Accuracy 0.1164\n",
            "Time taken for 1 epoch: 46.80835151672363 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.6592 Accuracy 0.1159\n",
            "Epoch 13 Batch 100 Loss 1.5946 Accuracy 0.1198\n",
            "Epoch 13 Batch 200 Loss 1.5942 Accuracy 0.1181\n",
            "Vaildation Epoch 13 Val_Loss 4.0957, Val_Acc 0.0797\n",
            "Saving checkpoint for epoch 13 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-40\n",
            "Epoch 13 Loss 1.5893 Accuracy 0.1184\n",
            "Time taken for 1 epoch: 46.567176818847656 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 1.5225 Accuracy 0.1270\n",
            "Epoch 14 Batch 100 Loss 1.5579 Accuracy 0.1220\n",
            "Epoch 14 Batch 200 Loss 1.5510 Accuracy 0.1198\n",
            "Vaildation Epoch 14 Val_Loss 4.1216, Val_Acc 0.0790\n",
            "Saving checkpoint for epoch 14 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-41\n",
            "Epoch 14 Loss 1.5469 Accuracy 0.1199\n",
            "Time taken for 1 epoch: 46.93642067909241 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 1.5093 Accuracy 0.1257\n",
            "Epoch 15 Batch 100 Loss 1.5153 Accuracy 0.1228\n",
            "Epoch 15 Batch 200 Loss 1.5097 Accuracy 0.1208\n",
            "Vaildation Epoch 15 Val_Loss 4.1655, Val_Acc 0.0785\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-42\n",
            "Epoch 15 Loss 1.5056 Accuracy 0.1211\n",
            "Time taken for 1 epoch: 46.84185433387756 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 1.4622 Accuracy 0.1302\n",
            "Epoch 16 Batch 100 Loss 1.4711 Accuracy 0.1247\n",
            "Epoch 16 Batch 200 Loss 1.4722 Accuracy 0.1224\n",
            "Vaildation Epoch 16 Val_Loss 4.1843, Val_Acc 0.0782\n",
            "Saving checkpoint for epoch 16 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-43\n",
            "Epoch 16 Loss 1.4704 Accuracy 0.1224\n",
            "Time taken for 1 epoch: 46.9870023727417 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 1.4408 Accuracy 0.1300\n",
            "Epoch 17 Batch 100 Loss 1.4433 Accuracy 0.1259\n",
            "Epoch 17 Batch 200 Loss 1.4421 Accuracy 0.1236\n",
            "Vaildation Epoch 17 Val_Loss 4.2155, Val_Acc 0.0773\n",
            "Saving checkpoint for epoch 17 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-44\n",
            "Epoch 17 Loss 1.4399 Accuracy 0.1237\n",
            "Time taken for 1 epoch: 46.79827046394348 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 1.3837 Accuracy 0.1277\n",
            "Epoch 18 Batch 100 Loss 1.4072 Accuracy 0.1270\n",
            "Epoch 18 Batch 200 Loss 1.4047 Accuracy 0.1247\n",
            "Vaildation Epoch 18 Val_Loss 4.2473, Val_Acc 0.0771\n",
            "Saving checkpoint for epoch 18 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-45\n",
            "Epoch 18 Loss 1.4031 Accuracy 0.1248\n",
            "Time taken for 1 epoch: 46.80476140975952 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 1.3205 Accuracy 0.1352\n",
            "Epoch 19 Batch 100 Loss 1.3799 Accuracy 0.1282\n",
            "Epoch 19 Batch 200 Loss 1.3733 Accuracy 0.1260\n",
            "Vaildation Epoch 19 Val_Loss 4.2677, Val_Acc 0.0774\n",
            "Saving checkpoint for epoch 19 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-46\n",
            "Epoch 19 Loss 1.3714 Accuracy 0.1261\n",
            "Time taken for 1 epoch: 46.742891788482666 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 1.2957 Accuracy 0.1347\n",
            "Epoch 20 Batch 100 Loss 1.3558 Accuracy 0.1286\n",
            "Epoch 20 Batch 200 Loss 1.3521 Accuracy 0.1265\n",
            "Vaildation Epoch 20 Val_Loss 4.2808, Val_Acc 0.0775\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-47\n",
            "Epoch 20 Loss 1.3501 Accuracy 0.1268\n",
            "Time taken for 1 epoch: 46.71813607215881 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 1.2790 Accuracy 0.1336\n",
            "Epoch 21 Batch 100 Loss 1.3308 Accuracy 0.1299\n",
            "Epoch 21 Batch 200 Loss 1.3263 Accuracy 0.1278\n",
            "Vaildation Epoch 21 Val_Loss 4.2908, Val_Acc 0.0777\n",
            "Saving checkpoint for epoch 21 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-48\n",
            "Epoch 21 Loss 1.3255 Accuracy 0.1279\n",
            "Time taken for 1 epoch: 46.98016595840454 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 1.3365 Accuracy 0.1300\n",
            "Epoch 22 Batch 100 Loss 1.3070 Accuracy 0.1306\n",
            "Epoch 22 Batch 200 Loss 1.3001 Accuracy 0.1286\n",
            "Vaildation Epoch 22 Val_Loss 4.3138, Val_Acc 0.0776\n",
            "Saving checkpoint for epoch 22 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-49\n",
            "Epoch 22 Loss 1.2973 Accuracy 0.1288\n",
            "Time taken for 1 epoch: 46.75313711166382 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 1.2428 Accuracy 0.1345\n",
            "Epoch 23 Batch 100 Loss 1.2857 Accuracy 0.1313\n",
            "Epoch 23 Batch 200 Loss 1.2782 Accuracy 0.1293\n",
            "Vaildation Epoch 23 Val_Loss 4.3118, Val_Acc 0.0783\n",
            "Saving checkpoint for epoch 23 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-50\n",
            "Epoch 23 Loss 1.2761 Accuracy 0.1295\n",
            "Time taken for 1 epoch: 46.775799036026 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 1.2188 Accuracy 0.1368\n",
            "Epoch 24 Batch 100 Loss 1.2611 Accuracy 0.1320\n",
            "Epoch 24 Batch 200 Loss 1.2544 Accuracy 0.1301\n",
            "Vaildation Epoch 24 Val_Loss 4.3498, Val_Acc 0.0783\n",
            "Saving checkpoint for epoch 24 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-51\n",
            "Epoch 24 Loss 1.2537 Accuracy 0.1302\n",
            "Time taken for 1 epoch: 46.845919132232666 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 1.2163 Accuracy 0.1352\n",
            "Epoch 25 Batch 100 Loss 1.2414 Accuracy 0.1333\n",
            "Epoch 25 Batch 200 Loss 1.2334 Accuracy 0.1312\n",
            "Vaildation Epoch 25 Val_Loss 4.3580, Val_Acc 0.0773\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-52\n",
            "Epoch 25 Loss 1.2333 Accuracy 0.1313\n",
            "Time taken for 1 epoch: 46.777848958969116 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 1.2036 Accuracy 0.1372\n",
            "Epoch 26 Batch 100 Loss 1.2155 Accuracy 0.1343\n",
            "Epoch 26 Batch 200 Loss 1.2134 Accuracy 0.1318\n",
            "Vaildation Epoch 26 Val_Loss 4.3829, Val_Acc 0.0772\n",
            "Saving checkpoint for epoch 26 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-53\n",
            "Epoch 26 Loss 1.2153 Accuracy 0.1318\n",
            "Time taken for 1 epoch: 46.777320861816406 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 1.1763 Accuracy 0.1393\n",
            "Epoch 27 Batch 100 Loss 1.1977 Accuracy 0.1349\n",
            "Epoch 27 Batch 200 Loss 1.1940 Accuracy 0.1327\n",
            "Vaildation Epoch 27 Val_Loss 4.3978, Val_Acc 0.0773\n",
            "Saving checkpoint for epoch 27 at ./checkpoints/w2w/unformated_en_2_formated_fr/cycle3/ckpt_virtual/ckpt-54\n",
            "Epoch 27 Loss 1.1953 Accuracy 0.1327\n",
            "Time taken for 1 epoch: 46.91320514678955 secs\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcAPwjbrYo9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = os.path.join(ckpt_path, \"log_real.npy\")\n",
        "os.makedirs(os.path.dirname(log_dir), exist_ok=True)\n",
        "np.save(log_dir, D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5buvMlnvyrFm",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder_input):\n",
        "\n",
        "  batch_size = encoder_input.shape[0]\n",
        "  output = np.array([decoder_v2id['<SOS>']]*batch_size).reshape(-1,1)\n",
        "  MAX_LENGTH = encoder_input.shape[-1]\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    # if predicted_id == tokenizer_en.vocab_size+1:\n",
        "    #   return output, attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=1)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onj-LdrNvtIn",
        "colab_type": "text"
      },
      "source": [
        "### BLEU Score Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USjPs21xxiAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_gen = get_gen(data=aligned_en, batch_size=256, valid_test=True)\n",
        "dec_gen = get_gen(data=aligned_fr, batch_size=256, valid_test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDBUoLJ-0zod",
        "colab_type": "code",
        "outputId": "bd72afde-117a-4603-a15e-4ca319485061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Sum = 0\n",
        "Total_n = 0\n",
        "for enc_data_words, dec_data_words in tqdm(zip(enc_gen, dec_gen)):\n",
        "    out_words = get_out(enc_data_words)\n",
        "    Sum += sum([sacrebleu.sentence_bleu(out_words[i], dec_data_words[i], smooth_method='exp').score for i in range(len(out_words))])\n",
        "    Total_n += len(out_words)\n",
        "    print(Sum/Total_n, \"Out of {} samples\".format(Total_n))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.28it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9.080982191884067 Out of 32 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.34it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.243383617461497 Out of 64 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.31it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.406684657254248 Out of 96 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.17it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.596373962801682 Out of 128 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.16it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.457721575393025 Out of 160 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.45it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.078704472678124 Out of 192 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.38it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.967388232537217 Out of 224 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.40it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.34643539926186 Out of 256 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.35it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.131618979790755 Out of 288 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.07it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.980514546764162 Out of 320 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.02it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.070646304882198 Out of 352 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.67it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.9450018456223965 Out of 384 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.62it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.914082628049472 Out of 416 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.43it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.9958987385007685 Out of 448 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.55it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.032312123283969 Out of 480 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 27.77it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.041884255990368 Out of 512 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.13it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.03938914773586 Out of 544 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.30it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.03096916622934 Out of 576 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.25it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 27.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.003058153868928 Out of 608 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.32it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.992309747141199 Out of 640 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.37it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.974636952142191 Out of 672 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.45it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.953247384079413 Out of 704 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.22it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.966264152122361 Out of 736 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.04it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.05452605220398 Out of 768 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.44it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8.026738715577949 Out of 800 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.30it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 27.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.988842643112449 Out of 832 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.22it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 27.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.983426633119138 Out of 864 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 27.86it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.961972617898437 Out of 896 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.39it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.964691633225309 Out of 928 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.64it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 32/32 [00:01<00:00, 28.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.935191097627071 Out of 960 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_zCe2v8lehs",
        "colab_type": "text"
      },
      "source": [
        "## Prediction and virtual file creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_36nPSVjoH5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_unaligned_en = '/content/drive/My Drive/ift6759/ift6759-t6-p2/data/cycle4/unaligned_unformated_en'\n",
        "new_unaligned_fr = '/content/drive/My Drive/ift6759/ift6759-t6-p2/data/cycle4/unaligned_formated_fr'\n",
        "os.makedirs(os.path.dirname(new_unaligned_en), exist_ok=True)\n",
        "os.makedirs(os.path.dirname(new_unaligned_fr), exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcd6IQVWmMSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_gen = get_gen(data=original_unaligned_en, batch_size=256, valid_test=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yjAfaBGlj7r",
        "colab_type": "code",
        "outputId": "7566eace-cacc-47e9-8289-f454317e6147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fa53052d9f9b49b7988e43691a6f25cc",
            "4ff43743d693467cb5ecb2c4c34fe62b",
            "c57b46ccdd404fceb0686a997a81c132",
            "bc76a5e4768d4cf393c94c2afed62063",
            "4a2fcdf19f254c11b05d25aca8e1570d",
            "93435c458c664099abb6025ba22d7d8c",
            "ac6341ed7b804e88baf5cd3f32162d0f",
            "81b1dfb14856459ca663f0bb167f02ea"
          ]
        }
      },
      "source": [
        "required = 100\n",
        "start_point = 0\n",
        "for i, enc_data_words in tqdm(enumerate(enc_gen), total=required):\n",
        "    if required is None or (i<required and i>=start_point):\n",
        "        try:\n",
        "            out_words = get_out(enc_data_words)\n",
        "        except Exception:\n",
        "            print(\"OOM\")\n",
        "            required += 1\n",
        "            continue\n",
        "        write_file_append(data=enc_data_words, output=new_unaligned_en)\n",
        "        write_file_append(data=out_words, output=new_unaligned_fr)"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa53052d9f9b49b7988e43691a6f25cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/512 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/512 [00:01<04:40,  1.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 18%|█▊        | 92/512 [00:01<02:42,  2.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 137/512 [00:01<01:41,  3.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 46%|████▋     | 238/512 [00:01<00:51,  5.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 64%|██████▍   | 329/512 [00:01<00:24,  7.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 512/512 [00:01<00:00, 308.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OOM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/512 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/512 [00:01<04:40,  1.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▍       | 126/512 [00:01<02:28,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 42%|████▏     | 215/512 [00:01<01:20,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 66%|██████▋   | 340/512 [00:01<00:32,  5.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 512/512 [00:01<00:00, 330.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OOM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/512 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/512 [00:01<04:38,  1.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 137/512 [00:01<02:23,  2.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|████▉     | 254/512 [00:01<01:09,  3.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 69%|██████▉   | 353/512 [00:01<00:29,  5.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 512/512 [00:01<00:00, 335.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OOM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/512 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/512 [00:01<04:39,  1.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 23%|██▎       | 117/512 [00:01<02:31,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 45%|████▍     | 229/512 [00:01<01:16,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 68%|██████▊   | 350/512 [00:01<00:30,  5.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 512/512 [00:01<00:00, 336.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-261-5c8625211bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequired\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mout_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_data_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OOM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-d6c40c27933e>\u001b[0m in \u001b[0;36mget_out\u001b[0;34m(enc_data_words)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_data_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0menc_data_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_data_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_data_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mout_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_v2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_v2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_data_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-250-82430a36d70f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder_input)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                  \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                  \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                  dec_padding_mask)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# select the last word from the seq_len dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-234-86245da83a7c>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     dec_output, attention_weights = self.decoder(\n\u001b[0;32m---> 21\u001b[0;31m         tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, tar_seq_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-189-40c5febbaf6d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n\u001b[0;32m---> 30\u001b[0;31m                                              look_ahead_mask, padding_mask)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer{}_block1'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-187-4da1df58ee9f>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     attn2, attn_weights_block2 = self.mha2(\n\u001b[0;32m---> 28\u001b[0;31m         enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mattn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-184-310c98019c19>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     scaled_attention, attention_weights = scaled_dot_product_attention(\n\u001b[0;32m---> 38\u001b[0;31m         q, k, v, mask)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len_q, num_heads, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-d4bc96e7f9bb>\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(q, k, v, mask)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mmatmul_qk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (..., seq_len_q, seq_len_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# scale matmul_qk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2944\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m       return gen_math_ops.batch_mat_mul_v2(\n\u001b[0;32m-> 2946\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   2947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1506\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   1507\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BatchMatMulV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         tld.op_callbacks, x, y, \"adj_x\", adj_x, \"adj_y\", adj_y)\n\u001b[0m\u001b[1;32m   1509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb67W9VFEWrq",
        "colab_type": "text"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CN-BV43FMBej",
        "colab": {}
      },
      "source": [
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "  sentence = tokenizer_pt.encode(sentence)\n",
        "  \n",
        "  attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "    \n",
        "    # plot the attention weights\n",
        "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "    \n",
        "    ax.set_xticks(range(len(sentence)+2))\n",
        "    ax.set_yticks(range(len(result)))\n",
        "    \n",
        "    ax.set_ylim(len(result)-1.5, -0.5)\n",
        "        \n",
        "    ax.set_xticklabels(\n",
        "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
        "        fontdict=fontdict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                        if i < tokenizer_en.vocab_size], \n",
        "                       fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lU2_yG_vBGza",
        "colab": {}
      },
      "source": [
        "def translate(sentence, plot=''):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  \n",
        "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
        "                                            if i < tokenizer_en.vocab_size])  \n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsxrAlvFG8SZ",
        "colab": {}
      },
      "source": [
        "translate(\"este é um problema que temos que resolver.\")\n",
        "print (\"Real translation: this is a problem we have to solve .\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7EH5y_aqI4t1",
        "colab": {}
      },
      "source": [
        "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
        "print (\"Real translation: and my neighboring homes heard about this idea .\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-hVCTSUMlkb",
        "colab": {}
      },
      "source": [
        "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
        "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_1MxkSZvz0jX"
      },
      "source": [
        "You can pass different layers and attention blocks of the decoder to the `plot` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t-kFyiOLH0xg",
        "colab": {}
      },
      "source": [
        "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
        "print (\"Real translation: this is the first book i've ever done.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    }
  ]
}