{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_transformer.ipynb","provenance":[],"collapsed_sections":["nb67W9VFEWrq"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1b125d7060fd4017a38f5f064ec3e9c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8b0df1d6bbbc4475bbc030a16991c20e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dfcda4a874ad4f18bd3ee415bd76587f","IPY_MODEL_009c9d6823214d318d741e1c133cddf7"]}},"8b0df1d6bbbc4475bbc030a16991c20e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfcda4a874ad4f18bd3ee415bd76587f":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_abb0b74fd6af45d697e9fd9883464eb6","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a76ed137966146b6a88b4a40dd202bce"}},"009c9d6823214d318d741e1c133cddf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d810ffb071bf40d7950a0f12b9a63fc5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28/28 [32:15&lt;00:00, 69.13s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46e71f24735741939c7bee5a1c593078"}},"abb0b74fd6af45d697e9fd9883464eb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a76ed137966146b6a88b4a40dd202bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d810ffb071bf40d7950a0f12b9a63fc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46e71f24735741939c7bee5a1c593078":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"sxLx0cxT_fJ7","colab_type":"text"},"source":["### Colab stuff"]},{"cell_type":"code","metadata":{"id":"BWqhS7vxL8sr","colab_type":"code","outputId":"a55fddf4-c3cf-48c1-df74-2ee6050a3095","executionInfo":{"status":"ok","timestamp":1587328227168,"user_tz":240,"elapsed":539,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oqoNO6SIMIir","colab_type":"code","outputId":"fd0c8a13-f6c5-4691-8f3a-04456cbb2387","executionInfo":{"status":"ok","timestamp":1587328234180,"user_tz":240,"elapsed":5696,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["!pip install gensim==3.8.1\n","!pip install sacrebleu"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.6/dist-packages (3.8.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.18.2)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.4.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.11.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.12.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (1.12.39)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.21.0)\n","Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.49.0)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (1.15.39)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.9.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (1.24.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim==3.8.1) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim==3.8.1) (2.8.1)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.6)\n","Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (0.996.5)\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.7.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sWdkK1xIL5IO","colab_type":"code","outputId":"ed8f2f3c-620a-4846-9efd-4415fa6211a7","executionInfo":{"status":"ok","timestamp":1587328234182,"user_tz":240,"elapsed":2191,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.chdir(os.path.join('drive', 'My Drive', 'project2'))\n","os.getcwd()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/project2'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"rYDRwI_X_oSc","colab_type":"text"},"source":["### imports"]},{"cell_type":"code","metadata":{"id":"BKXrS5VKKORC","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os\n","import json\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sacrebleu\n","\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import train_test_split\n","from utils.data import postprocessing\n","from utils.data import checkout_data\n","\n","from models.transformer import Transformer\n","from models.transformer.utils import create_masks\n","from utils.dataloader import encoder_preprocess, decoder_preprocess"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V3SG8WxB_q4E","colab_type":"text"},"source":["### Dataloader"]},{"cell_type":"code","metadata":{"id":"kLpPZX6_mevi","colab_type":"code","outputId":"9884ca7c-41a6-4dcf-e96d-f172cec41bd3","executionInfo":{"status":"ok","timestamp":1587324360282,"user_tz":240,"elapsed":51264,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["encoder_dataset, encoder_v2id, encoder_id2v = encoder_preprocess(data=\"data/aligned_unformated_en\")\n","decoder_dataset, decoder_v2id, decoder_id2v = decoder_preprocess(data=\"data/aligned_formated_fr\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11000/11000 [00:12<00:00, 858.54it/s] \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11000/11000 [00:14<00:00, 781.59it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"G5O3Lg1XKNia","colab_type":"code","colab":{}},"source":["(\n","    input_tensor_train,\n","    input_tensor_valid,\n","    target_tensor_train,\n","    target_tensor_valid\n",") = train_test_split(encoder_dataset, decoder_dataset, test_size=0.2, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YkYCU30nONMd","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","batch_size = 32\n","dataset_train = tf.data.Dataset.from_tensor_slices(\n","    (input_tensor_train, target_tensor_train)).batch(batch_size, drop_remainder=False)\n","dataset_valid = tf.data.Dataset.from_tensor_slices(\n","    (input_tensor_valid, target_tensor_valid)).batch(batch_size, drop_remainder=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P9-BgT6v_wyc","colab_type":"text"},"source":["#### View data sample"]},{"cell_type":"code","metadata":{"id":"otUIR4qqKp2W","colab_type":"code","outputId":"9b2e1b19-9674-46ba-b865-41e9aec4b5eb","executionInfo":{"status":"ok","timestamp":1587324361057,"user_tz":240,"elapsed":51898,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["for i,j in dataset_train:\n","  for z in i[10].numpy():\n","    print(encoder_id2v[z], end = ' ')\n","  print(\"\\n\")\n","  for z in j[10].numpy():\n","    print(decoder_id2v[z], end = ' ')\n","  print(\"\\n\")\n","  break\n","\n","for i,j in dataset_valid:\n","  for z in i[0].numpy():\n","    print(encoder_id2v[z], end = ' ')\n","  print(\"\\n\")\n","  for z in j[0].numpy():\n","    print(decoder_id2v[z], end = ' ')\n","  print(\"\\n\")\n","  break\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["<SOS> regulation applying a scheme of generalised tariff preferences vote <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n","\n","<SOS> <CAP> rÃ¨glement appliquant un schÃ©ma de prÃ©fÃ©rences tarifaires gÃ©nÃ©ralisÃ©es ( vote ) <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n","\n","<SOS> my wish is for you to help a strong sustainable movement to educate every child about food to inspire families to cook again and to empower people everywhere to fight obesity <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n","\n","<SOS> <CAP> mon souhait est que vous <UNK> un puissant mouvement durable pour Ã©duquer chaque enfant Ã  l â€™ alimentation , pour inspirer les familles Ã  cuisiner Ã  nouveau , et dynamiser les gens partout Ã  lutter contre l â€™ obÃ©sitÃ© . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J0Qjg6vuaHNt"},"source":["# Transformer model for language understanding"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wsINyf1VEQLC"},"source":["## Set hyperparameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lnJn5SLA2ahP","colab":{}},"source":["num_layers = 2\n","d_model = 128\n","dff = 512\n","num_heads = 16\n","\n","input_vocab_size = len(encoder_v2id) + 1\n","target_vocab_size = len(decoder_v2id) + 1\n","dropout_rate = 0.3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xYEGhEOtzn5W"},"source":["## Optimizer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7r4scdulztRx","colab":{}},"source":["from models.transformer.utils import CustomSchedule\n","\n","learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f33ZCgvHpPdG","outputId":"f245693b-cd2f-485a-cede-253056f34256","executionInfo":{"status":"ok","timestamp":1587324361465,"user_tz":240,"elapsed":52236,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["temp_learning_rate_schedule = CustomSchedule(d_model)\n","\n","plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YgkDE7hzo8r5"},"source":["## Loss and metrics"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MlhsJMm0TW_B","colab":{}},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"67oqVHiT0Eiu","colab":{}},"source":["def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"phlyxMnm-Tpx","colab":{}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='train_accuracy')\n","valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n","valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='valid_accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aeHumfr7zmMa"},"source":["## Training and checkpointing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UiysUa--4tOU","colab":{}},"source":["transformer = Transformer(num_layers, d_model, num_heads, dff,\n","                          input_vocab_size, target_vocab_size, \n","                          pe_input=input_vocab_size, \n","                          pe_target=target_vocab_size,\n","                          rate=dropout_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Fzuf06YZp66w"},"source":["Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hNhuYfllndLZ","colab":{}},"source":["checkpoint_path = \"./checkpoints/train/w2w/unformated_en_2_formated_fr\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wrdQau7Basv","colab_type":"code","colab":{}},"source":["# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iJwmp9OE29oj","colab":{}},"source":["# The @tf.function trace-compiles train_step into a TF graph for faster\n","# execution. The function specializes to the precise shape of the argument\n","# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n","# batch sizes (the last batch is smaller), use input_signature to specify\n","# more generic shapes.\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)\n","\n","@tf.function(input_signature=train_step_signature)\n","def valid_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","  predictions, _ = transformer(inp, tar_inp, \n","                                True, \n","                                enc_padding_mask, \n","                                combined_mask, \n","                                dec_padding_mask)\n","  loss = loss_function(tar_real, predictions)\n","  valid_loss(loss)\n","  valid_accuracy(tar_real, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnvwR9tZYz7A","colab_type":"code","colab":{}},"source":["EPOCHS = 28"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bbvmaKNiznHZ","outputId":"7830a6d8-c4f7-4e1c-e4b8-786b06376db5","executionInfo":{"status":"ok","timestamp":1587325719476,"user_tz":240,"elapsed":1409447,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1b125d7060fd4017a38f5f064ec3e9c3","8b0df1d6bbbc4475bbc030a16991c20e","dfcda4a874ad4f18bd3ee415bd76587f","009c9d6823214d318d741e1c133cddf7","abb0b74fd6af45d697e9fd9883464eb6","a76ed137966146b6a88b4a40dd202bce","d810ffb071bf40d7950a0f12b9a63fc5","46e71f24735741939c7bee5a1c593078"]}},"source":["for epoch in tqdm(range(EPOCHS)):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  valid_loss.reset_states()\n","  valid_accuracy.reset_states()\n","  \n","\n","  # inp -> portuguese, tar -> english\n","  for (batch, (inp, tar)) in enumerate(dataset_train):\n","    train_step(inp, tar)\n","    \n","    if batch % 100 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","\n","  for (batch, (v_inp, v_tar)) in enumerate(dataset_valid):\n","    valid_step(v_inp, v_tar)\n","\n","  print ('Vaildation Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, valid_loss.result(), valid_accuracy.result()))\n","\n","\n","  if (epoch + 1) % 5 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b125d7060fd4017a38f5f064ec3e9c3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 10.1364 Accuracy 0.0000\n","Epoch 1 Batch 100 Loss 10.0331 Accuracy 0.0021\n","Epoch 1 Batch 200 Loss 9.7372 Accuracy 0.0068\n","Vaildation Epoch 1 Loss 8.0679 Accuracy 0.0128\n","Epoch 1 Loss 9.4139 Accuracy 0.0084\n","Time taken for 1 epoch: 57.10968017578125 secs\n","\n","Epoch 2 Batch 0 Loss 8.0693 Accuracy 0.0118\n","Epoch 2 Batch 100 Loss 7.4125 Accuracy 0.0135\n","Epoch 2 Batch 200 Loss 6.9155 Accuracy 0.0136\n","Vaildation Epoch 2 Loss 6.0969 Accuracy 0.0190\n","Epoch 2 Loss 6.6989 Accuracy 0.0142\n","Time taken for 1 epoch: 48.93781661987305 secs\n","\n","Epoch 3 Batch 0 Loss 6.0898 Accuracy 0.0170\n","Epoch 3 Batch 100 Loss 5.9229 Accuracy 0.0256\n","Epoch 3 Batch 200 Loss 5.7624 Accuracy 0.0300\n","Vaildation Epoch 3 Loss 5.3199 Accuracy 0.0414\n","Epoch 3 Loss 5.6476 Accuracy 0.0326\n","Time taken for 1 epoch: 48.86228966712952 secs\n","\n","Epoch 4 Batch 0 Loss 5.2610 Accuracy 0.0412\n","Epoch 4 Batch 100 Loss 5.1366 Accuracy 0.0422\n","Epoch 4 Batch 200 Loss 5.0673 Accuracy 0.0421\n","Vaildation Epoch 4 Loss 4.9857 Accuracy 0.0459\n","Epoch 4 Loss 5.0182 Accuracy 0.0428\n","Time taken for 1 epoch: 48.61755013465881 secs\n","\n","Epoch 5 Batch 0 Loss 4.8303 Accuracy 0.0489\n","Epoch 5 Batch 100 Loss 4.7736 Accuracy 0.0470\n","Epoch 5 Batch 200 Loss 4.7330 Accuracy 0.0466\n","Vaildation Epoch 5 Loss 4.7956 Accuracy 0.0488\n","Saving checkpoint for epoch 5 at ./checkpoints/train/w2w/unformated_en_2_formated_fr/ckpt-1\n","Epoch 5 Loss 4.6998 Accuracy 0.0472\n","Time taken for 1 epoch: 49.35819935798645 secs\n","\n","Epoch 6 Batch 0 Loss 4.5658 Accuracy 0.0519\n","Epoch 6 Batch 100 Loss 4.5022 Accuracy 0.0508\n","Epoch 6 Batch 200 Loss 4.4704 Accuracy 0.0505\n","Vaildation Epoch 6 Loss 4.6587 Accuracy 0.0518\n","Epoch 6 Loss 4.4418 Accuracy 0.0511\n","Time taken for 1 epoch: 49.12758755683899 secs\n","\n","Epoch 7 Batch 0 Loss 4.3473 Accuracy 0.0516\n","Epoch 7 Batch 100 Loss 4.2818 Accuracy 0.0543\n","Epoch 7 Batch 200 Loss 4.2595 Accuracy 0.0538\n","Vaildation Epoch 7 Loss 4.5697 Accuracy 0.0538\n","Epoch 7 Loss 4.2387 Accuracy 0.0542\n","Time taken for 1 epoch: 49.15447998046875 secs\n","\n","Epoch 8 Batch 0 Loss 4.1380 Accuracy 0.0575\n","Epoch 8 Batch 100 Loss 4.1042 Accuracy 0.0574\n","Epoch 8 Batch 200 Loss 4.0855 Accuracy 0.0565\n","Vaildation Epoch 8 Loss 4.4928 Accuracy 0.0555\n","Epoch 8 Loss 4.0666 Accuracy 0.0569\n","Time taken for 1 epoch: 48.89840030670166 secs\n","\n","Epoch 9 Batch 0 Loss 3.9995 Accuracy 0.0582\n","Epoch 9 Batch 100 Loss 3.9462 Accuracy 0.0598\n","Epoch 9 Batch 200 Loss 3.9267 Accuracy 0.0592\n","Vaildation Epoch 9 Loss 4.4577 Accuracy 0.0568\n","Epoch 9 Loss 3.9092 Accuracy 0.0595\n","Time taken for 1 epoch: 48.925084829330444 secs\n","\n","Epoch 10 Batch 0 Loss 3.8603 Accuracy 0.0605\n","Epoch 10 Batch 100 Loss 3.7957 Accuracy 0.0623\n","Epoch 10 Batch 200 Loss 3.7746 Accuracy 0.0616\n","Vaildation Epoch 10 Loss 4.4313 Accuracy 0.0579\n","Saving checkpoint for epoch 10 at ./checkpoints/train/w2w/unformated_en_2_formated_fr/ckpt-2\n","Epoch 10 Loss 3.7580 Accuracy 0.0620\n","Time taken for 1 epoch: 49.5837459564209 secs\n","\n","Epoch 11 Batch 0 Loss 3.7031 Accuracy 0.0650\n","Epoch 11 Batch 100 Loss 3.6411 Accuracy 0.0652\n","Epoch 11 Batch 200 Loss 3.6212 Accuracy 0.0643\n","Vaildation Epoch 11 Loss 4.4007 Accuracy 0.0586\n","Epoch 11 Loss 3.6051 Accuracy 0.0645\n","Time taken for 1 epoch: 47.48725605010986 secs\n","\n","Epoch 12 Batch 0 Loss 3.5498 Accuracy 0.0684\n","Epoch 12 Batch 100 Loss 3.5014 Accuracy 0.0674\n","Epoch 12 Batch 200 Loss 3.4778 Accuracy 0.0668\n","Vaildation Epoch 12 Loss 4.3646 Accuracy 0.0601\n","Epoch 12 Loss 3.4644 Accuracy 0.0670\n","Time taken for 1 epoch: 47.49992918968201 secs\n","\n","Epoch 13 Batch 0 Loss 3.4031 Accuracy 0.0688\n","Epoch 13 Batch 100 Loss 3.3547 Accuracy 0.0706\n","Epoch 13 Batch 200 Loss 3.3317 Accuracy 0.0699\n","Vaildation Epoch 13 Loss 4.3599 Accuracy 0.0612\n","Epoch 13 Loss 3.3152 Accuracy 0.0702\n","Time taken for 1 epoch: 47.55399513244629 secs\n","\n","Epoch 14 Batch 0 Loss 3.2314 Accuracy 0.0731\n","Epoch 14 Batch 100 Loss 3.2187 Accuracy 0.0732\n","Epoch 14 Batch 200 Loss 3.1919 Accuracy 0.0724\n","Vaildation Epoch 14 Loss 4.3362 Accuracy 0.0636\n","Epoch 14 Loss 3.1778 Accuracy 0.0729\n","Time taken for 1 epoch: 47.18504977226257 secs\n","\n","Epoch 15 Batch 0 Loss 3.0994 Accuracy 0.0761\n","Epoch 15 Batch 100 Loss 3.0684 Accuracy 0.0767\n","Epoch 15 Batch 200 Loss 3.0497 Accuracy 0.0756\n","Vaildation Epoch 15 Loss 4.3308 Accuracy 0.0651\n","Saving checkpoint for epoch 15 at ./checkpoints/train/w2w/unformated_en_2_formated_fr/ckpt-3\n","Epoch 15 Loss 3.0343 Accuracy 0.0760\n","Time taken for 1 epoch: 48.12389922142029 secs\n","\n","Epoch 16 Batch 0 Loss 2.9277 Accuracy 0.0824\n","Epoch 16 Batch 100 Loss 2.9264 Accuracy 0.0800\n","Epoch 16 Batch 200 Loss 2.9006 Accuracy 0.0790\n","Vaildation Epoch 16 Loss 4.2908 Accuracy 0.0665\n","Epoch 16 Loss 2.8838 Accuracy 0.0795\n","Time taken for 1 epoch: 47.5513014793396 secs\n","\n","Epoch 17 Batch 0 Loss 2.8222 Accuracy 0.0813\n","Epoch 17 Batch 100 Loss 2.7757 Accuracy 0.0837\n","Epoch 17 Batch 200 Loss 2.7544 Accuracy 0.0825\n","Vaildation Epoch 17 Loss 4.3147 Accuracy 0.0669\n","Epoch 17 Loss 2.7424 Accuracy 0.0827\n","Time taken for 1 epoch: 47.39598298072815 secs\n","\n","Epoch 18 Batch 0 Loss 2.7296 Accuracy 0.0849\n","Epoch 18 Batch 100 Loss 2.6359 Accuracy 0.0873\n","Epoch 18 Batch 200 Loss 2.6216 Accuracy 0.0859\n","Vaildation Epoch 18 Loss 4.3082 Accuracy 0.0677\n","Epoch 18 Loss 2.6079 Accuracy 0.0862\n","Time taken for 1 epoch: 47.38871097564697 secs\n","\n","Epoch 19 Batch 0 Loss 2.5171 Accuracy 0.0901\n","Epoch 19 Batch 100 Loss 2.5159 Accuracy 0.0904\n","Epoch 19 Batch 200 Loss 2.4977 Accuracy 0.0890\n","Vaildation Epoch 19 Loss 4.3239 Accuracy 0.0680\n","Epoch 19 Loss 2.4846 Accuracy 0.0895\n","Time taken for 1 epoch: 47.55971145629883 secs\n","\n","Epoch 20 Batch 0 Loss 2.4658 Accuracy 0.0924\n","Epoch 20 Batch 100 Loss 2.3976 Accuracy 0.0937\n","Epoch 20 Batch 200 Loss 2.3838 Accuracy 0.0922\n","Vaildation Epoch 20 Loss 4.3237 Accuracy 0.0687\n","Saving checkpoint for epoch 20 at ./checkpoints/train/w2w/unformated_en_2_formated_fr/ckpt-4\n","Epoch 20 Loss 2.3743 Accuracy 0.0925\n","Time taken for 1 epoch: 48.04032063484192 secs\n","\n","Epoch 21 Batch 0 Loss 2.3878 Accuracy 0.0967\n","Epoch 21 Batch 100 Loss 2.2962 Accuracy 0.0964\n","Epoch 21 Batch 200 Loss 2.2827 Accuracy 0.0948\n","Vaildation Epoch 21 Loss 4.3580 Accuracy 0.0690\n","Epoch 21 Loss 2.2752 Accuracy 0.0951\n","Time taken for 1 epoch: 47.96704912185669 secs\n","\n","Epoch 22 Batch 0 Loss 2.2844 Accuracy 0.0947\n","Epoch 22 Batch 100 Loss 2.2096 Accuracy 0.0990\n","Epoch 22 Batch 200 Loss 2.1981 Accuracy 0.0973\n","Vaildation Epoch 22 Loss 4.3673 Accuracy 0.0690\n","Epoch 22 Loss 2.1873 Accuracy 0.0976\n","Time taken for 1 epoch: 47.812278747558594 secs\n","\n","Epoch 23 Batch 0 Loss 2.1703 Accuracy 0.1019\n","Epoch 23 Batch 100 Loss 2.1265 Accuracy 0.1014\n","Epoch 23 Batch 200 Loss 2.1192 Accuracy 0.0998\n","Vaildation Epoch 23 Loss 4.3884 Accuracy 0.0694\n","Epoch 23 Loss 2.1103 Accuracy 0.1000\n","Time taken for 1 epoch: 47.73248243331909 secs\n","\n","Epoch 24 Batch 0 Loss 2.1129 Accuracy 0.1014\n","Epoch 24 Batch 100 Loss 2.0453 Accuracy 0.1040\n","Epoch 24 Batch 200 Loss 2.0396 Accuracy 0.1022\n","Vaildation Epoch 24 Loss 4.4111 Accuracy 0.0691\n","Epoch 24 Loss 2.0330 Accuracy 0.1024\n","Time taken for 1 epoch: 47.84534978866577 secs\n","\n","Epoch 25 Batch 0 Loss 2.0321 Accuracy 0.1037\n","Epoch 25 Batch 100 Loss 1.9836 Accuracy 0.1055\n","Epoch 25 Batch 200 Loss 1.9785 Accuracy 0.1039\n","Vaildation Epoch 25 Loss 4.4203 Accuracy 0.0692\n","Saving checkpoint for epoch 25 at ./checkpoints/train/w2w/unformated_en_2_formated_fr/ckpt-5\n","Epoch 25 Loss 1.9721 Accuracy 0.1042\n","Time taken for 1 epoch: 48.33655095100403 secs\n","\n","Epoch 26 Batch 0 Loss 1.9944 Accuracy 0.1044\n","Epoch 26 Batch 100 Loss 1.9271 Accuracy 0.1075\n","Epoch 26 Batch 200 Loss 1.9166 Accuracy 0.1060\n","Vaildation Epoch 26 Loss 4.4295 Accuracy 0.0700\n","Epoch 26 Loss 1.9096 Accuracy 0.1063\n","Time taken for 1 epoch: 48.00228142738342 secs\n","\n","Epoch 27 Batch 0 Loss 1.8946 Accuracy 0.1121\n","Epoch 27 Batch 100 Loss 1.8658 Accuracy 0.1096\n","Epoch 27 Batch 200 Loss 1.8545 Accuracy 0.1081\n","Vaildation Epoch 27 Loss 4.4646 Accuracy 0.0703\n","Epoch 27 Loss 1.8513 Accuracy 0.1082\n","Time taken for 1 epoch: 47.791661977767944 secs\n","\n","Epoch 28 Batch 0 Loss 1.8602 Accuracy 0.1123\n","Epoch 28 Batch 100 Loss 1.8090 Accuracy 0.1120\n","Epoch 28 Batch 200 Loss 1.7991 Accuracy 0.1102\n","Vaildation Epoch 28 Loss 4.4678 Accuracy 0.0708\n","Epoch 28 Loss 1.7939 Accuracy 0.1103\n","Time taken for 1 epoch: 47.6854567527771 secs\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QfcsSWswSdGV"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"3PeYTeif2o71","colab_type":"code","outputId":"92b5e4ef-77b7-415d-fb4b-7125a3d3bc64","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587328287702,"user_tz":240,"elapsed":46375,"user":{"displayName":"Ma N","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuwSPcGbEHIaM_WOruEx4vyO3N3-Ci-ijqOQkX_g=s64","userId":"15545994265930077321"}}},"source":["!python evaluator.py --target-file-path data/output.txt --input-file-path data/input.txt"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2020-04-19 20:30:42.686183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","100% 11000/11000 [00:12<00:00, 891.68it/s] \n","100% 11000/11000 [00:12<00:00, 853.15it/s] \n","2020-04-19 20:31:18.263645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-19 20:31:18.281058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.281712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2020-04-19 20:31:18.281765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-19 20:31:18.281829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-19 20:31:18.281860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-19 20:31:18.281890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-19 20:31:18.281917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-19 20:31:18.282951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-19 20:31:18.283043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-19 20:31:18.283188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.283776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.284274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-04-19 20:31:18.289744: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n","2020-04-19 20:31:18.289989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ddb2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-19 20:31:18.290014: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-19 20:31:18.393504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.394214: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ddb100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-19 20:31:18.394245: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-04-19 20:31:18.394502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.395108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2020-04-19 20:31:18.395175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-19 20:31:18.395204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-19 20:31:18.395224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-19 20:31:18.395241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-19 20:31:18.395257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-19 20:31:18.395309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-19 20:31:18.395326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-19 20:31:18.395436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.396050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.396563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2020-04-19 20:31:18.396616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-19 20:31:18.805345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-19 20:31:18.805400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n","2020-04-19 20:31:18.805421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n","2020-04-19 20:31:18.805699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.806347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-19 20:31:18.806893: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-19 20:31:18.806943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","Latest checkpoint restored!!\n","0it [00:00, ?it/s]\n","100% 4/4 [00:00<00:00, 67923.95it/s]\n","2020-04-19 20:31:22.337986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","\n","100% 4/4 [00:00<00:00, 70789.94it/s]\n","1it [00:07,  7.80s/it]\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.final_layer.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.final_layer.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.embedding.embeddings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.embedding.embeddings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.layernorm3.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.layernorm3.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.layernorm3.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.layernorm3.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.mha.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.mha.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha1.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.mha2.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha1.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.mha2.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.final_layer.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.final_layer.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.embedding.embeddings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.embedding.embeddings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.layernorm3.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.layernorm3.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.layernorm1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.layernorm1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.layernorm2.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.layernorm2.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.layernorm3.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.layernorm3.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.mha.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.0.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.mha.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.encoder.enc_layers.1.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha1.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.mha2.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.0.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha1.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.wq.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.wq.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.wk.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.wk.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.wv.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.wv.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.dense.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.mha2.dense.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-1.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).transformer.decoder.dec_layers.1.ffn.layer_with_weights-1.bias\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","final avg bleu score: 3.30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yBCdTNDkIs2Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}